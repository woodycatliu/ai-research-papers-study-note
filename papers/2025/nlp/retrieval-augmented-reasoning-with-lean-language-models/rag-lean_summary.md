# 檢索增強生成與推理整合的輕量級語言模型技術報告

---

## 📝 **結構優化**

### **1. 核心目標與方法**

本技術報告詳述了一種新穎的方法，旨在將**檢索增強生成 (RAG)** 和**推理**整合到單一的**輕量級語言模型 (LLM)** 架構中。這項工作的核心目標是在資源受限或安全環境中，部署高效能且保護隱私的解決方案。

核心方法包括：

* **輕量級骨幹模型**：採用 **Qwen2.5-Instruct 模型**（1.5B 至 32B 參數）。
* **密集檢索器**：與上述模型整合，用於從外部知識庫中檢索相關資訊。
* **合成數據生成**：利用如 DeepSeek-R1 或 GPT-4o 等前沿模型，從策劃的語料庫（本例為 NHS A-to-Z 病症頁面）生成**合成查詢**和**推理追蹤**。
* **推理感知微調**：探索摘要文件壓縮、合成數據設計和推理感知微調對模型性能的影響。

### **2. 背景與相關工作**

本研究回顧了三個主要領域，為其方法提供了理論基礎：

* **測試時擴展 (Test-time scaling)**：透過增加推論期間的計算資源來提升語言模型性能。包括**並行生成**和**序列擴展**（如思維鏈提示）。
* **檢索增強生成 (RAG)**：由**檢索器**和**生成器**組成，透過從外部知識庫檢索資訊來提高 LLM 的**事實性**、**可驗證性**和減少**幻覺**。
* **輕量級語言模型**：因數據隱私和資源限制而生，透過**量化**、**剪枝**和**知識蒸餾**等技術減小模型尺寸，以利於本地部署。

### **3. 系統架構與實施**

本研究的系統設置涵蓋了多個關鍵組件：

* **計算資源**：使用 **16 個 NVIDIA A100 80GB GPU** 進行訓練。
* **輕量級語言模型**：採用 **Qwen2.5-Instruct 模型**，實驗發現**14B 參數**的模型在推理能力上才有顯著收益。
* **檢索系統**：使用基於嵌入的方法，採用 **sentence-transformers/all-mpnet-base-v2** 和 **Chroma 向量數據庫**，並實施**完整文件檢索**以確保上下文的完整性。
* **合成數據生成**：利用 **GPT-4o** 生成多樣化的**基本**、**疑病**和**輕描淡寫**類型查詢，並使用 **DeepSeek-R1** 生成推理追蹤和最終答案。
* **微調**：使用這些推理追蹤對 Qwen2.5-Instruct 模型進行**監督式微調**，並透過**自動文件摘要**將平均詞元長度從 74,641 減少到 7,544，以解決上下文過長問題。

### **4. 對話式介面**

本研究將所有組件整合，創建了一個流暢的多輪互動系統。

* **聊天互動編排**：使用 **LangChain 框架**開發 RAG 管道，將微調後的模型作為聊天代理。
* **檢索作為工具**：模型被視為**代理 (agent)**，並能自主決定是否調用檢索工具，有效解決多輪對話中的**歧義問題**和**不必要檢索**。
* **前端介面**：基於 Svelte 框架的靜態網頁，類似於 ChatGPT，用戶可查看推理追蹤。

### **5. 示範應用：NHS A-to-Z 病症知識庫**

本研究將其方法應用於 NHS 病症數據集，驗證其在專業決策支援領域的潛力。

* **數據集**：收集並處理了 **990 個 NHS 病症頁面**。
* **檢索性能**：**摘要版本**的文件一致地帶來更高的檢索準確率（k=5 時為 0.76），優於完整頁面（0.68）。
* **病症與下一步行動預測**：經領域內微調的 **t0-1.1-k5-32B 模型**在**病症準確性**方面達到 **56%**，與前沿大型推理模型相當。

### **6. 討論與未來展望**

* **通用型與領域特定推理器**：研究強調**領域特定推理追蹤**的重要性，經此微調的模型在性能上比通用模型高出 **3% 到 12%**。
* **進一步縮小模型尺寸的蒸餾**：透過知識蒸餾，**1.5B 參數的模型也能保持與 32B 參數非推理模型相當的性能**，使得這些模型可在消費級設備上運行。
* **結論**：本報告成功展示了在單一輕量級模型中有效結合推理和檢索增強生成的方法。該模型在領域特定決策任務中表現出色，並顯著優於未經領域特定微調的小型推理模型。