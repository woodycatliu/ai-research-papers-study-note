# 透過精簡語言模型實現檢索增強型推理

Ryan Sze-Yin Chan $^{1}$、Federico Nanni $^{1}$、Tomas Lazauskas $^{1}$、Rosie Wood $^{1}$、Penelope Yong $^{1}$、Lionel Tarassenko $^{2}$、Mark Girolami $^{1,3}$、James Geddes $^{1}$、Andrew Duncan $^{4}$ $^{1}$ The Alan Turing Institute、$^{2}$ 牛津大學、$^{3}$ 劍橋大學、$^{4}$ 倫敦帝國學院

通訊作者：{rchan,fnanni,jgeddes}@turing.ac.uk a.duncan@imperial.ac.uk

# 摘要

本技術報告詳細介紹了一種新穎的方法，在單一、精簡的語言模型架構中結合推理和檢索增強生成（RAG）。雖然現有的 RAG 系統通常依賴大型模型和外部 API，但我們的工作旨在滿足日益增長的需求，為在資源受限或安全環境中部署提供高效能且保護隱私的解決方案。我們基於測試時間擴展和小型推理模型的最新發展，開發了一種檢索增強型對話代理，能夠使用輕量級骨幹模型解釋複雜的特定領域查詢。我們的系統將密集檢索器與經過微調的 Qwen2.5-Instruct 模型整合，利用從前沿模型（例如 DeepSeek-R1）針對精選語料庫（本例中為 NHS A-to-Z 狀況頁面）衍生的合成查詢生成和推理追蹤。我們探討了基於摘要的文件壓縮、合成資料設計以及推理感知微調對模型效能的影響。對比非推理型和通用型精簡模型的評估表明，我們的特定領域微調方法在答案準確性和一致性方面取得了顯著提升，其效能接近前沿水平，同時仍能實現本地部署。所有實作細節和程式碼均已公開發布，以支援跨領域的重現性和適應性。

# 1 引言

近期旨在提高語言模型測試時間效能的努力已顯示出巨大的潛力 [1, 2, 3, 4]。這些方法，特別是那些透過思維鏈提示 [5] 增強所謂「推理」能力的方法，已使相對小型的模型（例如 DeepSeek-R1 蒸餾模型 [6] 或 s1 [7]）在特定任務中獲得與前沿模型（例如 OpenAI 的產品 [8]）相當的結果。

同時，專注於透過檢索增強生成（RAG）策略提高 LLM 輸出真實性和可驗證性的工作，為減少幻覺 [9, 10, 11] 提供了明確的機會，特別是在處理特定知識領域的複雜性時 [12, 13]。

推理和 RAG 的成功整合如今已廣泛應用於如 ChatGPT 和 Gemini 等工具中。對於給定的使用者查詢，這些系統可以先對查詢進行推理，然後決定採取行動（例如執行網路搜尋或查詢 Google 地圖等工具），最後才返回最終答案。這種形式的推理和工具使用是新興代理式 AI 系統的特徵 [14, 15, 16]。另一種方法是，系統可能首先檢索與使用者查詢相關的文件，然後對收集到的證據進行推理後再回應。本技術報告將重點關注第二種方法——**先檢索後推理**。

儘管檢索和推理的結合在通用應用中顯著增強了前沿語言模型的效能，但當使用者不願意或無法與外部實體共享資料時，這種方法會遇到明顯的限制——特別是在涉及敏感或私人資訊的領域。即使模型的訓練資料是公開可用的，使用者提出的提示也常常包含高度專有或敏感的資訊，這些資訊不能跨越組織或國家邊界。

在這種情況下，有必要將語言模型部署在本地基礎設施上，可能是在安全或空氣隔離的環境中。為了滿足這些要求，近年來在開發開放可用的大型語言模型（例如 [17, 18, 19]）和檢索增強生成開源框架方面取得了穩步進展$^1$。最近，小型推理模型也開始出現 [6, 7]。儘管如此，有效整合推理能力以解釋檢索到的證據——特別是在輕量級或可本地部署模型的限制下——仍然是一個開放的研究挑戰。雖然 ReAct [20]、REPLUG [21] 和 MemGPT [22] 等近期的一些工作探索了混合架構，以強力整合 LLM 推理與文件檢索，但它們大多處於大型、非本地模型設定中。

為了解決這些限制，本技術報告提出了一種在單一精簡語言模型中有效結合推理和檢索增強生成的方法。此外，我們將這個經過微調的模型整合到一個互動式對話系統中，以展示其在下游任務中的適用性。所產生的系統特別適合處理涉及私人、特定領域知識庫上的複雜查詢的應用。在這種設定中，推理組件有助於解釋和分解複雜的查詢，而檢索機制則將模型限制在可驗證的資訊上，從而減輕幻覺回應的風險。我們對私人和敏感領域的關注促使我們強調精簡語言模型，這些模型可以由小型組織或政府部門在運算受限或安全環境中進行微調和部署。

本報告的結構如下。首先，我們概述了與該任務相關的測試時間擴展策略和相關工作。接著，詳細描述我們的系統架構，包括實作選擇和重現性的實用指導，並提供配套程式碼庫的參考。然後，我們展示了將我們的方法應用於一個具代表性的特定領域知識庫——**NHS A-to-Z 狀況網頁** $^2$——使用一組需要檢索和推理能力的查詢。報告最後討論了潛在的未來增強功能。我們方法的開源實作可在 GitHub 上獲得 $^3$，使從業者能夠將該系統應用於涉及結合檢索與結構化推理的特定領域問答的廣泛問題。

# 2 相關工作

在以下部分，我們概述了與本技術報告相關的研究領域。

# 2.1 測試時間擴展

測試時間擴展的核心概念是透過在推理期間增加運算資源，而不是在預訓練期間，來增強大型語言模型（LLM）的效能。先前的工作已經證明，這種策略可以比在預訓練階段增加運算更有效地提高效能 [2, 4]。在實踐中，測試時間擴展指的是部署推理時間策略，利用額外的採樣、運算或提示工程來提升固定模型的能力——無需透過微調或強化學習修改其參數。

一類廣泛使用的測試時間擴展方法是**平行生成**，其中模型生成多個候選回應，然後透過選擇機制進行聚合，例如多數投票 [3]、自洽性 [23] 或最佳 $N$ 採樣 [24]。這些技術透過利用模型輸出的多樣性來提高穩健性和事實準確性，選擇基於啟發式或學會的獎勵函數。其他常見策略，如 **束搜尋** [25] 和 **蒙地卡羅樹搜尋** [26]，平行維護一個序列的多個高機率延續，以探索更優化的生成。雖然這些方法通常能提高可能性，但與基於採樣的方法相反，它們可能會降低多樣性。

另一種補充方法稱為**序列擴展**，它涉及增加模型在得出最終答案之前所採取的**中間推理步驟**數量。最突出的例子是**思維鏈提示** [5]，其中模型被引導產生中間推理步驟，以提高在複雜任務上的效能。這種趨勢促成了模型行為的更廣泛擬人化，通常被描述為「推理」[27]。諸如**思維樹提示**等擴展，則透過在分支結構中探索多個推理路徑來概括這個想法，可能應用於評分和修剪機制來選擇最有前途的軌跡。更進階的測試時間擴展方法，在於它們是否假設可存取**驗證器**——一個可以對輸出進行評分、重新排序或驗證的模型或模組。在無驗證器設定中，選擇依賴於內部模型啟發式（例如多數投票、自洽性），而驗證器輔助設定則可以使用外部獎勵模型、分類器甚至人類來評估和選擇回應，從而導致更高的精確度但增加複雜性。

最近的模型，如 **DeepSeek-R1-Zero** [6]，透過強化學習訓練 LLM 以產生結構化的推理路徑，使用格式約定（例如將思想封裝在 `<think>` 標籤中）來輔助下游推理對齊，從而將這一前沿向前推進。儘管這個模型展示了強大的推理能力，但也表現出實際限制，例如可讀性下降和偶爾混用語言。

為了緩解這些挑戰，DeepSeek-R1 在強化學習（RL）之前融入了少量高品質的「冷啟動」資料。該資料集包含精心策劃的範例，最著名的是思維鏈演示，旨在穩定早期訓練並改善生成輸出的連貫性。DeepSeek-R1 隨後透過兩階段 RL 程序進行訓練：第一階段旨在提高推理能力，而第二階段則專注於將模型輸出與人類偏好對齊，從而增強可讀性並減少不連貫的補全。這種多階段訓練策略使 DeepSeek-R1 在一系列推理基準測試中達到與 OpenAI 的 o1 模型相當的效能。

儘管在過去兩年中開發各種推理模型方面付出了巨大努力，但對這些模型的評估在大多數情況下仍然僅限於一系列廣為人知的數學和編碼基準測試，這給讀者一種印象，即語言建模的推理實際上只意味著解決數學難題$^4$ [28]。然而，推理模型的下游應用也可以專注於規劃和決策，其中生成的推理追蹤可以洞察模型的策略，儘管過度依賴思維鏈作為模型答案的解釋存在缺陷 [29, 30, 31, 32]。

![](https://cdn-mineru.openxlab.org.cn/result/2025-08-24/68b0ebd8-97f1-4de9-8a4f-ac0495ec80bd/a06aa3506fe7d063cfc012687be52fb4092c50f924877acac2b71f41981e5d35.jpg)  
圖 1：標準的檢索增強生成管線。

# 2.2 檢索增強生成

一個檢索增強生成（RAG）系統有兩個關鍵組件（如圖 1 所示）：

1. **檢索器**：從某些外部記憶來源檢索資訊。這也涉及對知識庫進行索引的預處理步驟。
2. **生成器**：通常是一個 LLM，它根據檢索到的資訊生成回應。

RAG 讓 LLM 能夠從外部知識庫中檢索相關的文件塊，通常透過語義相似性和基於嵌入的方法 [10]。透過利用外部知識庫，RAG 使模型能夠將其回應基於相關上下文，而無需額外的訓練或微調，從而有效地幫助它生成相關回應並減少幻覺 [9]。

RAG 系統的成功在很大程度上取決於其檢索器的品質，其作用是為 LLM 提供來自外部資料庫中最相關的資訊。檢索器有兩個核心功能：

1. **索引**：對資料進行預處理和分塊，以便資料可以快速檢索。
2. **查詢**：檢索與給定查詢相關的資料。

儘管外部資料來源可能有多種形式——包括多模態資料（例如圖片、影片、音訊）、表格資料集和結構化知識圖，但本報告僅關注外部記憶由**文本文件語料庫**組成的情況。在這種設定中，通常需要**文件分塊**，將每個文件分割成更小、更易於管理的片段，以符合檢索中使用的嵌入模型和生成中使用的語言模型的上下文視窗限制。一種常見的方法是根據預定義的單位（如字元、段落或來自特定分詞器的標記序列）來分割文件。通常採用**重疊塊**來減少在邊界上分割語義重要內容的風險。

為了支援這種情況下的檢索，我們採用一種**基於嵌入**的方法，該方法利用向量儲存：一種專門的資料結構，設計用於根據其向量表示（或嵌入）高效地索引和檢索項目。這些嵌入旨在捕捉輸入文本的語義內容，並用於表示各個文件塊。在查詢時，系統將輸入查詢嵌入到相同的向量空間中，並對儲存的文件嵌入執行相似性搜尋，以識別語義上最相關的段落。常見的相似性度量包括**歐幾里德距離**和**餘弦相似性**，後者測量兩個向量之間夾角的餘弦，並因其尺度不變性而常被優先選擇。

已經開發了更進階的技術來改善檢索內容和使用者查詢之間的相關性和上下文對齊。其中一種方法是**上下文檢索** [33]，其中生成簡短的解釋性上下文並在嵌入和索引之前附加到每個文件塊，保留了在文件被分割成更小片段時會丟失的重要上下文資訊。此外，檢索過程不僅可以根據查詢本身，還可以根據額外上下文（例如先前的對話輪次或任務的不斷演變的狀態）進行條件化 [34, 35]。這使得檢索器能夠返回與互動意圖和話語結構更緊密對齊的段落。此外，通常採用**重新排序機制**來精煉初始檢索輸出 [36]。這些重新排序器通常作為輕量級神經模型或交叉編碼器實作，透過聯合考量查詢和每個文件塊來更精確地評分一組檢索到的候選段落，從而改進選擇傳遞給生成器的最有資訊的上下文。

最近的工作也探索了**檢索器-生成器共同訓練**，其中兩個組件在閉環中共同或迭代地進行訓練 [37]。這可以導致檢索和生成之間更緊密的耦合，檢索器學習優先處理生成器可以最有效地作為條件來產生準確和連貫回應的段落。此外，**多跳檢索**透過鏈接多個檢索步驟來擴展 RAG 範式，允許系統從文件中的不同來源聚合證據 [38]。總體而言，這些技術正朝著**檢索感知推理**的方向發展，其中檢索過程不僅針對相關性進行優化，也針對支援結構化推理和忠實生成進行優化。

# 2.3 精簡語言模型

前沿語言模型規模的日益增大導致了自然語言處理（NLP）研究的轉變，這些模型通常透過專用 API 作為服務存取 [39, 40]。這種**模型即服務**的方法有時是唯一可用的選項，特別是對於像 OpenAI 提供的那些閉源模型。當大型開源模型發布時，例如 4050 億參數的 Llama 3.1 [41] 或 6710 億參數的 DeepSeek-R1 模型 [6]，即使僅用於推理，其運算需求也常常讓許多研究團隊和小型組織望而卻步。因此，基於雲端的 LLM 端點，例如由 Microsoft Azure 提供的，提供了一種與這些模型互動的實用且可存取的方式。

然而，這種方法不適用於資料是私有或敏感且必須保留在本地的環境。在這種情況下，將資料傳送到第三方 API 不是一個可行的選擇。這促使了**小型語言模型**的開發和部署，旨在在資源受限的環境中高效運作，同時保持競爭力。通常採用**量化** [42]、**剪枝** [43] 和**知識蒸餾** [44, 45] 等技術來減少模型大小和運算需求。

特別是，**知識蒸餾**，即訓練一個較小的「學生」模型來複製較大「教師」模型的行為，已顯示出在減少 LLM 大小同時保持整體良好效能方面的巨大潛力。例如，**Gemma 2** 模型 [46] 的大小從 20 億到 270 億參數不等，設計用於高效的自然語言理解和生成任務。雖然較大的變體是從頭開始訓練的，但較小的變體，例如 2B 和 9B 模型，利用來自較大 27B 模型的知識蒸餾來實現競爭性效能。

當目的是獲得推理模型的小型版本時，也採用了這些策略 [47]。例如，DeepSeek 團隊 [6] 使用知識蒸餾來創建其 DeepSeek-R1 模型的蒸餾版本，採用 Qwen 和 Llama 作為起始 LLM，並使用 80 萬個樣本。s1 團隊 [7] 提出的另一種策略是，作者僅對 1,000 個推理追蹤（最初來自 s1 中的 Gemini Flash Thinking，然後是 s1.1 中的 DeepSeek）微調了 32B Qwen 模型，這凸顯了策劃一小組選定訓練資料與大量更嘈雜的範例池相比的重要性。

這些策略為**精簡語言模型**鋪平了道路，作為大規模萬億參數前沿模型的自然對立點。小型語言模型的優勢已被廣泛認可，特別是在**代理式系統**的背景下 [48, 49]。透過測試時間擴展等策略來創建高能力精簡模型的新穎演算法創新，是一個非常活躍的研究領域。

在本技術報告中，我們在這些先前工作的基礎上，重點關注如何增強小型語言模型中的**域內推理能力**，該模型將獲得一系列文件以解決使用者查詢。

# 3 系統設定

在本節中，我們將概述我們的系統，涵蓋其所有方面，從所需的運算基礎設施到管線設計和用於聊天互動的前端介面。

# 3.1 運算資源

在本技術報告中，我們介紹了在一套可供相對小型研究實驗室和產業團隊使用的設定中微調精簡推理模型的方法，該設定不依賴於大型基礎設施。我們盡可能嚴格遵循了 s1 [7] 中描述的配置，並使用了 16 個 NVIDIA A100 80 GB GPU 來訓練最大型的模型。需要這種硬體配置來訓練 32B 模型，主要是由於訓練期間採用的**大上下文視窗**（區塊大小 = 32768 標記）。需要如此長的上下文視窗，以確保模型能夠依賴（通常很長$^5$）的推理追蹤，以及檢索到的文件，來產生對使用者查詢的答案。

A100 80 GB GPU 提供的記憶體和效能特性與 s1 研究中使用的 NVIDIA H100s 夠接近，使其成為類似工作負載的可行替代方案。我們在 Microsoft Azure 和兩個英國學術高效能運算（HPC）平台 **Baskerville**$^6$ 和 **Isambard-AI**$^7$ [50] 上進行了實驗，評估了各種配置。此外，我們還利用了 Microsoft Azure 的 AI Foundry，這是一套旨在簡化與基礎模型整合的工具和 API。

**Microsoft Azure**。我們使用了兩台類型為 `8Standard ND96amsr A100 v4` 的虛擬機器，每台提供：
- 96 個 vCPU 和 1800 GB 系統記憶體
- 每個 VM 8 個 NVIDIA A100 80GB GPU

這些 VM 為大型模型微調提供了出色的記憶體利用率。我們發現，每個節點使用 8 個 GPU，特別是兩個節點各有 8 個 GPU（總共 16 個 GPU）來微調 32B 模型，由於更緊密的 GPU 耦合和更好的記憶體飽和度，導致訓練更有效率。相比之下，每個節點只有 4 個 GPU 的 HPC 系統需要在更多節點上進行分散式訓練，例如 Isambard-AI 上的 6 個節點（總共 24 個 GPU），這會引入額外的開銷並降低效率。

透過 Azure AI Foundry，我們存取了以下模型的推理端點：
- OpenAI API 模型：GPT-4o, o3-mini
- DeepSeek 模型：DeepSeek-R1

這些端點實現了推理追蹤和合成使用者查詢的高效生成，以及對前沿 LLM 的最終效能測試。

**Baskerville**。額外的實驗是在 Baskerville 上進行的，這是由伯明罕大學託管的 GPU 集群。每個節點包含：
- 4 個 NVIDIA A100 GPU（40GB 或 80GB），透過 NVLink 3.0 連接
- 節點之間的高頻寬 InfiniBand HDR 互連

我們也可以使用帶有 NVIDIA H100 80GB GPU 的探索性節點，這些節點用於選定的微調和評估運行。

**Isambard-AI Phase 1**。我們還在 Isambard-AI 上進行了實驗，這是英國國家 AI 研究運算平台之一。Isambard-AI 的第一階段由 42 個基於 `arch64` 架構的節點組成。每個節點包括：
- 4 個 NVIDIA GH200 Grace Hopper 超級晶片
- 每個超級晶片結合了一個 Grace CPU 和一個 Hopper H100 GPU
- Slingshot 11 高速互連（每個節點 4 個 Cassini NIC，每個 200 Gbps）

**運算用量總結**。在不同的平台上，我們大約使用了：
- Isambard-AI 上 700 個 GPU 小時
- Baskerville 上 500 個 GPU 小時
- Microsoft Azure 上 2500 個 GPU 小時

這些運算資源使得能夠在模型大小、微調策略和推理配置上進行全面的實驗。最終 32B 參數模型的微調持續了大約 80 個 GPU 小時。

# 3.2 管線概覽

我們的管線包含多個步驟：使用向量資料庫索引一個集合；透過向量相似性檢索文件以回應使用者查詢，對獲得的結果進行推理，最後生成答案。在本節中，我們將介紹管線的每個步驟，從系統的核心部分——所使用的語言模型開始。

# 3.2.1 精簡語言模型

根據先前在測試時間擴展 [3, 7] 方面的研究，我們也採用 **Qwen2.5-Instruct** 模型，因為它們具有全面的競爭效能、擴展的上下文長度和開源可用性。特別是，我們在此重點關注從 1.5B 到 32B 參數範圍的模型，以了解不同規模下模型的能力。在圖 2 中，我們透過遵循 [7] 中描述的相同訓練程序，在不同模型大小上重現了 s1.1* 微調，並檢查了模型在（數學推理）**AIME24** $^{10}$ 基準測試上的效能。

在這種設定中，當採用至少 14B 參數的模型時，推理能力的好處顯而易見，而對於較小的模型（1.5B），微調過程最終會對模型效能產生負面影響。儘管作者也提出了一種預算強制方法來控制測試時間運算，透過強制終止模型的思考過程或在模型試圖結束時附加 "Wait" 來延長其生成，但在這個初步實驗中我們沒有應用它，以便能夠比較不同規模的基線推理能力。

# 3.2.2 檢索系統

如第 2.2 節所述，檢索增強生成（RAG）系統有兩個關鍵組件：**檢索器**和**生成器**。對於我們的檢索器，我們使用基於嵌入的方法，其中文件塊被索引並使用**句子轉換器模型** [51] 給予向量嵌入。為了查詢向量資料庫，執行相似性搜尋以識別前 $k$ 個最相似的塊。

作為預設的嵌入模型，我們採用 `sentence-transformers/all-mpnet-base-v2`。該模型有 1.09 億個參數，並將句子和段落映射到一個 768 維的向量空間。該模型的最大序列長度為 384 個標記。請注意，在將我們的文件分割成塊時，我們預設使用 50 個標記的塊重疊。在實踐中，我們發現這個句子轉換器模型在提供良好效能的同時，也快速且便宜用於推理。

![](https://cdn-mineru.openxlab.org.cn/result/2025-08-24/68b0ebd8-97f1-4de9-8a4f-ac0495ec80bd/0a4fef0d44520d38d906c0072bb20d5648f79781450e1d336ca93f91ea38f3c0.jpg)  
圖 2：Qwen2.5-Instruct 模型及其後訓練版本在 AIME24 上的效能，後者是在 DeepSeek-R1 推理追蹤上進行微調的（重現 s1.1 工作，遵循 [7]）。

我們使用 **Chroma** $^{11}$ 向量資料庫，它預設使用 $l^2$-範數相似性分數度量。在我們的程式碼庫中，我們也提供了讓使用者使用替代的句子轉換器模型和選擇使用 **FAISS** [52] 資料庫的選項。在我們的用例中，我們發現 Chroma 和 FAISS 提供了相似的檢索效能，但 Chroma 稍微快一些。

我們的檢索系統使用**完整文件檢索**，如果某個特定文件的任何塊被發現在前 $k$ 個塊集合中，我們的系統將繼續檢索該塊來源的整個原始文件。這確保了 LLM 接收到圍繞相關資訊的完整上下文，即使最初只有一小部分文件被標記為相關。

# 3.2.3 合成資料生成

給定一個文件集合，我們使用一個語言模型來生成一系列查詢，這些查詢是：(a) 與集合中選定的文件相關；(b) 依賴理解文件內容中的資訊以提供有效答案。透過這種方式，我們能夠生成大量使用者請求，並預先知道正確答案（即特定文件和文件中的特定資訊）。為了建立一個具有挑戰性的評估資料集，我們也提示模型產生更複雜的查詢，例如模糊的使用者請求。有關這方面的更多細節將在實驗部分描述的個案研究中給出。

在我們的實驗中，我們依賴 **OpenAI 的 GPT-4o** 來生成一組高品質查詢，以測試我們系統的有用性，但我們的程式碼庫允許使用者自訂他們自己的設定，例如模型的選擇、提示範本和要生成的查詢數量。這樣使用者也可以使用本地 LLM 進行此步驟。

# 3.2.4 推理追蹤

給定一個合成生成的查詢和一組從我們的集合中檢索到的文件，我們提示一個大型推理模型以獲得其**推理追蹤**和最終答案。對於此步驟，我們在實驗中使用了 **DeepSeek-R1**，但使用者可以輕鬆選擇不同的推理模型。透過這個過程，我們生成了一個**推理追蹤資料集**，每個追蹤都包含一個查詢、一組檢索到的文件、推理過程和模型的最終答案。

# 3.2.5 微調

我們使用推理追蹤來**微調一個較小的模型**，以增強其在測試時的能力。目標是模型應該在提供最終答案之前開始產生類似於 DeepSeek-R1 的「推理過程」，並且該推理過程應該能改善整體效能。

我們遵循 s1 [7] 中描述的方法，並對 Qwen2.5-Instruct 模型（範圍從 1.5 到 32B 參數）的下一個標記預測執行**監督式微調**，使用基本的超參數。主要的挑戰，也區分了我們與 s1 的設定，是我們每個模型回應都比 s1 資料集中的長得多，因為它們包含推理追蹤和一組檢索到的文件。這是由於我們檢索的是完整文件而不是像第 3.2.2 節所述的塊。特別是，在我們首次嘗試將檢索到的文件數量設定為 5 來創建推理追蹤時，使用 Qwen2.5 分詞器的訓練範例的平均標記長度為 74641。相比之下，s1K $^{12}$ 和 s1K-1.1 $^{13}$ 資料集的平均標記長度分別為 9109 和 26969。為了在保持相同運算資源的情況下訓練我們的模型，我們採用了**自動文件摘要**，以減少輸入上下文的長度，同時仍能受益於檢索到的材料。

為了在保持相同運算資源的情況下訓練我們的模型，我們採用了**自動文件摘要**，以減少輸入上下文的長度，同時仍能受益於檢索到的材料。

# 3.2.6 檢索文件摘要

為了使訓練過程成為可能，我們透過特別處理我們集合中原始文件的大小來減少上下文的長度，同時保持其核心資訊。我們採用了 **Qwen2.5-32B-Instruct** 來生成我們集合中每個文件的摘要版本，將每個文件的大小減少到其原始長度的 85%。在我們的實驗中，我們還確保這對檢索效能沒有影響，但使用者應評估這在其他應用中是否一致。透過使用摘要文件，我們推理追蹤的平均標記長度減少到 7544。

一種替代基本文件摘要的方法是**查詢感知文件摘要**，即在檢索每個文件後，動態地對其進行摘要。這樣，摘要過程就會知道要保留哪些部分（與使用者查詢相關的部分）以及要從摘要中排除哪些部分。但請注意，這會減慢系統速度，因為對於每個使用者查詢來說，這將是一個額外的 LLM 行動，而我們的情況則是一個靜態的、摘要版本的集合。

# 3.3 對話介面

在接下來的部分，我們將描述如何連接所有這些元素，以實現系統與使用者之間流暢的多輪互動。

# 3.3.1 聊天互動的編排

為了將所有這些組件整合在一起，我們使用 Python 中的 **LangChain** $^{14}$ 框架來開發我們的 RAG 管線，並將其與我們微調的語言模型結合，創建一個對話聊天機器人應用程式。

對於我們的 RAG 應用程式，我們希望允許使用者進行來回對話，其中語言模型獲得先前的對話歷史和檢索到的上下文來建構回應。為了合併歷史訊息，必須使用對話歷史和一個**提示範本**。提示範本將原始的使用者/人類-AI 聊天互動轉換為語言模型可以處理並生成回應的格式。通常，聊天範本是特定於語言模型的，這意味著不同的語言模型系列，如 Llama [41]、Gemma [19, 46] 和 Qwen [17, 53] 使用不同的聊天範本。例如，對於 Qwen2.5-Instruct 模型，使用以下格式來指示給定互動的角色和內容：

`<|im_start|>{role} {content}<|im_end>`

角色可以是 `user`、`assistant` 或 `system` 之一。系統訊息對於指示模型執行某些動作或採用不同特徵（例如使用的語氣或風格）很有用。給定一個使用者-AI 聊天互動列表，我們可以**使用 Qwen 提示範本**來建構一個給語言模型的提示，例如：

`<|im_start|>system 你是一個樂於助人的助手。<|im_end>`
`<|im_start|>user 你好<|im_end>`
`<|im_start|>assistant 你好！我今天能幫你什麼忙嗎？<|im_end>`

為了向模型呈現從知識庫中檢索到的上下文，我們可以建構一個**系統提示範本**（參見附錄 A.1 中我們用於第 4 節描述的示例應用的系統提示），該範本定義了模型的任務，並呈現了檢索到的上下文以及額外資訊，例如使用者的背景。

請注意，我們也可以使用**使用者提示範本**，其中檢索到的上下文呈現在使用者訊息中。我們選擇不這樣做是為了限制對話歷史上下文長度的增長，因為在使用者訊息中呈現檢索到的上下文會導致隨著聊天的發展，檢索到的上下文保留在對話歷史中。在我們的案例中，當使用檢索時，檢索到的上下文會以系統提示的形式提供給模型，因此它可以在整個對話中有所不同。

此處使用的語言模型都具有有限的上下文視窗。因此，隨著對話累積長訊息歷史，可能需要**減少聊天歷史的大小**。我們透過根據標記計數來修剪歷史來實現這一點。請注意，我們從不從歷史中刪除系統提示，並且只在必要時刪除最舊的聊天互動。

# 3.3.2 檢索作為工具

在標準的 RAG 設定中，我們可能只需將最後一則使用者訊息作為檢索器的查詢。然而，這種簡單方法有兩個關鍵問題。

首先，在許多對話互動中，使用者訊息本身不足以作為檢索器的有用查詢。這種情況的常見情況是基於先前對話歷史的**後續問題**。例如，考慮以下對話：

**使用者**：我最近一直頭痛，有哪些常見方法可以緩解頭痛？
**AI**：緩解緊張性頭痛的常見方法包括服用非處方止痛藥，如布洛芬或對乙醯氨基酚，在頭部或頸部敷上溫熱或冰冷的敷布，以及練習放鬆技巧。
**使用者**：我在哪裡可以買到它們？

在標準的 RAG 設定中，如果沒有完整的對話上下文，查詢「我在哪裡可以買到它們？」是模糊不清的。

其次，通常使用者訊息可能足夠簡單，以至於模型不需要檢索。例如，對於「你好」這樣簡單的使用者訊息，避免檢索並讓模型直接回應會更便宜。

為了解決這兩個問題，可以將檢索視為模型可以存取的一個**工具**。就我們的目的而言，一個工具是一個函式與其模式的關聯，該模式定義了函式的名稱、描述和引數。然後，這個模式被傳遞給語言模型，而語言模型可以透過定義要使用的工具名稱和要使用的引數來決定使用該工具。這種方法利用了**工具呼叫**$^{15}$（有時稱為函式呼叫），現在許多現代聊天模型和端點提供者都普遍支援這種功能。

在這種設定中，我們將語言模型稱為**代理** [20, 54]，它將語言生成與行動相結合。通常，代理指任何可以感知其環境並對該環境採取行動的東西 [55]。代理可以執行的行動集由它可以存取的工具定義。對於我們的 RAG 管線，語言模型可以被視為一個代理，而工具就是**文本檢索器**。因此，對於給定的使用者訊息，模型可以決定# 透過精簡語言模型實現檢索增強型推理

Ryan Sze-Yin Chan $^{1}$、Federico Nanni $^{1}$、Tomas Lazauskas $^{1}$、Rosie Wood $^{1}$、Penelope Yong $^{1}$、Lionel Tarassenko $^{2}$、Mark Girolami $^{1,3}$、James Geddes $^{1}$、Andrew Duncan $^{4}$ $^{1}$ The Alan Turing Institute、$^{2}$ 牛津大學、$^{3}$ 劍橋大學、$^{4}$ 倫敦帝國學院

通訊作者：{rchan,fnanni,jgeddes}@turing.ac.uk a.duncan@imperial.ac.uk

# 摘要

本技術報告詳細介紹了一種新穎的方法，在單一、精簡的語言模型架構中結合推理和檢索增強生成（RAG）。雖然現有的 RAG 系統通常依賴大型模型和外部 API，但我們的工作旨在滿足日益增長的需求，為在資源受限或安全環境中部署提供高效能且保護隱私的解決方案。我們基於測試時間擴展和小型推理模型的最新發展，開發了一種檢索增強型對話代理，能夠使用輕量級骨幹模型解釋複雜的特定領域查詢。我們的系統將密集檢索器與經過微調的 Qwen2.5-Instruct 模型整合，利用從前沿模型（例如 DeepSeek-R1）針對精選語料庫（本例中為 NHS A-to-Z 狀況頁面）衍生的合成查詢生成和推理追蹤。我們探討了基於摘要的文件壓縮、合成資料設計以及推理感知微調對模型效能的影響。對比非推理型和通用型精簡模型的評估表明，我們的特定領域微調方法在答案準確性和一致性方面取得了顯著提升，其效能接近前沿水平，同時仍能實現本地部署。所有實作細節和程式碼均已公開發布，以支援跨領域的重現性和適應性。

# 1 引言

近期旨在提高語言模型測試時間效能的努力已顯示出巨大的潛力 [1, 2, 3, 4]。這些方法，特別是那些透過思維鏈提示 [5] 增強所謂**「推理」**能力的方法，已使相對小型的模型（例如 DeepSeek-R1 蒸餾模型 [6] 或 s1 [7]）在特定任務中獲得與前沿模型（例如 OpenAI 的產品 [8]）相當的結果。

同時，專注於透過檢索增強生成（RAG）策略提高 LLM 輸出真實性和可驗證性的工作，為減少幻覺 [9, 10, 11] 提供了明確的機會，特別是在處理特定知識領域的複雜性時 [12, 13]。

推理和 RAG 的成功整合如今已廣泛應用於如 **ChatGPT** 和 **Gemini** 等工具中。對於給定的使用者查詢，這些系統可以先對查詢進行推理，然後決定採取行動（例如執行網路搜尋或查詢 Google 地圖等工具），最後才返回最終答案。這種形式的推理和工具使用是新興代理式 AI 系統的特徵 [14, 15, 16]。另一種方法是，系統可能首先檢索與使用者查詢相關的文件，然後對收集到的證據進行推理後再回應。本技術報告將重點關注第二種方法——**先檢索後推理**。

儘管檢索和推理的結合在通用應用中顯著增強了前沿語言模型的效能，但當使用者不願意或無法與外部實體共享資料時，這種方法會遇到明顯的限制——特別是在涉及敏感或私人資訊的領域。即使模型的訓練資料是公開可用的，使用者提出的提示也常常包含高度專有或敏感的資訊，這些資訊不能跨越組織或國家邊界。

在這種情況下，有必要將語言模型部署在本地基礎設施上，可能是在安全或空氣隔離的環境中。為了滿足這些要求，近年來在開發開放可用的大型語言模型（例如 [17, 18, 19]）和檢索增強生成開源框架方面取得了穩步進展$^1$。最近，小型推理模型也開始出現 [6, 7]。儘管如此，有效整合推理能力以解釋檢索到的證據——特別是在輕量級或可本地部署模型的限制下——仍然是一個開放的研究挑戰。雖然 **ReAct** [20]、**REPLUG** [21] 和 **MemGPT** [22] 等近期的一些工作探索了混合架構，以強力整合 LLM 推理與文件檢索，但它們大多處於大型、非本地模型設定中。

為了解決這些限制，本技術報告提出了一種在單一精簡語言模型中有效結合推理和檢索增強生成的方法。此外，我們將這個經過微調的模型整合到一個互動式對話系統中，以展示其在下游任務中的適用性。所產生的系統特別適合處理涉及私人、特定領域知識庫上的複雜查詢的應用。在這種設定中，推理組件有助於解釋和分解複雜的查詢，而檢索機制則將模型限制在可驗證的資訊上，從而減輕幻覺回應的風險。我們對私人和敏感領域的關注促使我們強調精簡語言模型，這些模型可以由小型組織或政府部門在運算受限或安全環境中進行微調和部署。

本報告的結構如下。首先，我們概述了與該任務相關的測試時間擴展策略和相關工作。接著，詳細描述我們的系統架構，包括實作選擇和重現性的實用指導，並提供配套程式碼庫的參考。然後，我們展示了將我們的方法應用於一個具代表性的特定領域知識庫——**NHS A-to-Z 狀況網頁** $^2$——使用一組需要檢索和推理能力的查詢。報告最後討論了潛在的未來增強功能。我們方法的開源實作可在 GitHub 上獲得 $^3$，使從業者能夠將該系統應用於涉及結合檢索與結構化推理的特定領域問答的廣泛問題。

# 2 相關工作

在以下部分，我們概述了與本技術報告相關的研究領域。

# 2.1 測試時間擴展

測試時間擴展的核心概念是透過在推理期間增加運算資源，而不是在預訓練期間，來增強大型語言模型（LLM）的效能。先前的工作已經證明，這種策略可以比在預訓練階段增加運算更有效地提高效能 [2, 4]。在實踐中，測試時間擴展指的是部署推理時間策略，利用額外的採樣、運算或提示工程來提升固定模型的能力——無需透過微調或強化學習修改其參數。

一類廣泛使用的測試時間擴展方法是**平行生成**，其中模型生成多個候選回應，然後透過選擇機制進行聚合，例如多數投票 [3]、自洽性 [23] 或最佳 $N$ 採樣 [24]。這些技術透過利用模型輸出的多樣性來提高穩健性和事實準確性，選擇基於啟發式或學會的獎勵函數。其他常見策略，如**束搜尋** [25] 和**蒙地卡羅樹搜尋** [26]，平行維護一個序列的多個高機率延續，以探索更優化的生成。雖然這些方法通常能提高可能性，但與基於採樣的方法相反，它們可能會降低多樣性。

另一種補充方法稱為**序列擴展**，它涉及增加模型在得出最終答案之前所採取的**中間推理步驟**數量。最突出的例子是**思維鏈提示** [5]，其中模型被引導產生中間推理步驟，以提高在複雜任務上的效能。這種趨勢促成了模型行為的更廣泛擬人化，通常被描述為**「推理」**[27]。諸如**思維樹提示**等擴展，則透過在分支結構中探索多個推理路徑來概括這個想法，可能應用於評分和修剪機制來選擇最有前途的軌跡。更進階的測試時間擴展方法，在於它們是否假設可存取**驗證器**——一個可以對輸出進行評分、重新排序或驗證的模型或模組。在無驗證器設定中，選擇依賴於內部模型啟發式（例如多數投票、自洽性），而驗證器輔助設定則可以使用外部獎勵模型、分類器甚至人類來評估和選擇回應，從而導致更高的精確度但增加複雜性。

最近的模型，如 **DeepSeek-R1-Zero** [6]，透過強化學習訓練 LLM 以產生結構化的推理路徑，使用格式約定（例如將思想封裝在 `<think>` 標籤中）來輔助下游推理對齊，從而將這一前沿向前推進。儘管這個模型展示了強大的推理能力，但也表現出實際限制，例如可讀性下降和偶爾混用語言。

為了緩解這些挑戰，DeepSeek-R1 在強化學習（RL）之前融入了少量高品質的**「冷啟動」**資料。該資料集包含精心策劃的範例，最著名的是思維鏈演示，旨在穩定早期訓練並改善生成輸出的連貫性。DeepSeek-R1 隨後透過兩階段 RL 程序進行訓練：第一階段旨在提高推理能力，而第二階段則專注於將模型輸出與人類偏好對齊，從而增強可讀性並減少不連貫的補全。這種多階段訓練策略使 DeepSeek-R1 在一系列推理基準測試中達到與 OpenAI 的 o1 模型相當的效能。

儘管在過去兩年中開發各種推理模型方面付出了巨大努力，但對這些模型的評估在大多數情況下仍然僅限於一系列廣為人知的數學和編碼基準測試，這給讀者一種印象，即語言建模的推理實際上只意味著解決數學難題$^4$ [28]。然而，推理模型的下游應用也可以專注於規劃和決策，其中生成的推理追蹤可以洞察模型的策略，儘管過度依賴思維鏈作為模型答案的解釋存在缺陷 [29, 30, 31, 32]。

![](https://cdn-mineru.openxlab.org.cn/result/2025-08-24/68b0ebd8-97f1-4de9-8a4f-ac0495ec80bd/a06aa3506fe7d063cfc012687be52fb4092c50f924877acac2b71f41981e5d35.jpg)
圖 1：標準的檢索增強生成管線。

# 2.2 檢索增強生成

一個檢索增強生成（RAG）系統有兩個關鍵組件（如圖 1 所示）：

1.  **檢索器**：從某些外部記憶來源檢索資訊。這也涉及對知識庫進行索引的預處理步驟。
2.  **生成器**：通常是一個 LLM，它根據檢索到的資訊生成回應。

RAG 讓 LLM 能夠從外部知識庫中檢索相關的文件塊，通常透過語義相似性和基於嵌入的方法 [10]。透過利用外部知識庫，RAG 使模型能夠將其回應基於相關上下文，而無需額外的訓練或微調，從而有效地幫助它生成相關回應並減少幻覺 [9]。

RAG 系統的成功在很大程度上取決於其檢索器的品質，其作用是為 LLM 提供來自外部資料庫中最相關的資訊。檢索器有兩個核心功能：

1.  **索引**：對資料進行預處理和分塊，以便資料可以快速檢索。
2.  **查詢**：檢索與給定查詢相關的資料。

儘管外部資料來源可能有多種形式——包括多模態資料（例如圖片、影片、音訊）、表格資料集和結構化知識圖，但本報告僅關注外部記憶由**文本文件語料庫**組成的情況。在這種設定中，通常需要**文件分塊**，將每個文件分割成更小、易於管理的片段，以符合檢索中使用的嵌入模型和生成中使用的語言模型的上下文視窗限制。一種常見的方法是根據預定義的單位（如字元、段落或來自特定分詞器的標記序列）來分割文件。通常採用**重疊塊**來減少在邊界上分割語義重要內容的風險。

為了支援這種情況下的檢索，我們採用一種**基於嵌入**的方法，該方法利用向量儲存：一種專門的資料結構，設計用於根據其向量表示（或嵌入）高效地索引和檢索項目。這些嵌入旨在捕捉輸入文本的語義內容，並用於表示各個文件塊。在查詢時，系統將輸入查詢嵌入到相同的向量空間中，並對儲存的文件嵌入執行相似性搜尋，以識別語義上最相關的段落。常見的相似性度量包括**歐幾里德距離**和**餘弦相似性**，後者測量兩個向量之間夾角的餘弦，並因其尺度不變性而常被優先選擇。

已經開發了更進階的技術來改善檢索內容和使用者查詢之間的相關性和上下文對齊。其中一種方法是**上下文檢索** [33]，其中生成簡短的解釋性上下文並在嵌入和索引之前附加到每個文件塊，保留了在文件被分割成更小片段時會丟失的重要上下文資訊。此外，檢索過程不僅可以根據查詢本身，還可以根據額外上下文（例如先前的對話輪次或任務的不斷演變的狀態）進行條件化 [34, 35]。這使得檢索器能夠返回與互動意圖和話語結構更緊密對齊的段落。此外，通常採用**重新排序機制**來精煉初始檢索輸出 [36]。這些重新排序器通常作為輕量級神經模型或交叉編碼器實作，透過聯合考量查詢和每個文件塊來更精確地評分一組檢索到的候選段落，從而改進選擇傳遞給生成器的最有資訊的上下文。

最近的工作也探索了**檢索器-生成器共同訓練**，其中兩個組件在閉環中共同或迭代地進行訓練 [37]。這可以導致檢索和生成之間更緊密的耦合，檢索器學習優先處理生成器可以最有效地作為條件來產生準確和連貫回應的段落。此外，**多跳檢索**透過鏈接多個檢索步驟來擴展 RAG 範式，允許系統從文件中的不同來源聚合證據 [38]。總體而言，這些技術正朝著**檢索感知推理**的方向發展，其中檢索過程不僅針對相關性進行優化，也針對支援結構化推理和忠實生成進行優化。

# 2.3 精簡語言模型

前沿語言模型規模的日益增大導致了自然語言處理（NLP）研究的轉變，這些模型通常透過專用 API 作為服務存取 [39, 40]。這種**模型即服務**的方法有時是唯一可用的選項，特別是對於像 OpenAI 提供的那些閉源模型。當大型開源模型發布時，例如 4050 億參數的 Llama 3.1 [41] 或 6710 億參數的 DeepSeek-R1 模型 [6]，即使僅用於推理，其運算需求也常常讓許多研究團隊和小型組織望而卻步。因此，基於雲端的 LLM 端點，例如由 Microsoft Azure 提供的，提供了一種與這些模型互動的實用且可存取的方式。

然而，這種方法不適用於資料是私有或敏感且必須保留在本地的環境。在這種情況下，將資料傳送到第三方 API 不是一個可行的選擇。這促使了**小型語言模型**的開發和部署，旨在在資源受限的環境中高效運作，同時保持競爭力。通常採用**量化** [42]、**剪枝** [43] 和**知識蒸餾** [44, 45] 等技術來減少模型大小和運算需求。

特別是，**知識蒸餾**，即訓練一個較小的**「學生」**模型來複製較大**「教師」**模型的行為，已顯示出在減少 LLM 大小同時保持整體良好效能方面的巨大潛力。例如，**Gemma 2** 模型 [46] 的大小從 20 億到 270 億參數不等，設計用於高效的自然語言理解和生成任務。雖然較大的變體是從頭開始訓練的，但較小的變體，例如 2B 和 9B 模型，利用來自較大 27B 模型的知識蒸餾來實現競爭性效能。

當目的是獲得推理模型的小型版本時，也採用了這些策略 [47]。例如，DeepSeek 團隊 [6] 使用知識蒸餾來創建其 DeepSeek-R1 模型的蒸餾版本，採用 Qwen 和 Llama 作為起始 LLM，並使用 80 萬個樣本。s1 團隊 [7] 提出的另一種策略是，作者僅對 1,000 個推理追蹤（最初來自 s1 中的 Gemini Flash Thinking，然後是 s1.1 中的 DeepSeek）微調了 32B Qwen 模型，這凸顯了策劃一小組選定訓練資料與大量更嘈雜的範例池相比的重要性。

這些策略為**精簡語言模型**鋪平了道路，作為大規模萬億參數前沿模型的自然對立點。小型語言模型的優勢已被廣泛認可，特別是在**代理式系統**的背景下 [48, 49]。透過測試時間擴展等策略來創建高能力精簡模型的新穎演算法創新，是一個非常活躍的研究領域。

在本技術報告中，我們在這些先前工作的基礎上，重點關注如何增強小型語言模型中的**域內推理能力**，該模型將獲得一系列文件以解決使用者查詢。

# 3 系統設定

在本節中，我們將概述我們的系統，涵蓋其所有方面，從所需的運算基礎設施到管線設計和用於聊天互動的前端介面。

# 3.1 運算資源

在本技術報告中，我們介紹了在一套可供相對小型研究實驗室和產業團隊使用的設定中微調精簡推理模型的方法，該設定不依賴於大型基礎設施。我們盡可能嚴格遵循了 s1 [7] 中描述的配置，並使用了 16 個 NVIDIA A100 80 GB GPU 來訓練最大型的模型。需要這種硬體配置來訓練 32B 模型，主要是由於訓練期間採用的**大上下文視窗**（區塊大小 = 32768 標記）。需要如此長的上下文視窗，以確保模型能夠依賴（通常很長$^5$）的推理追蹤，以及檢索到的文件，來產生對使用者查詢的答案。

A100 80 GB GPU 提供的記憶體和效能特性與 s1 研究中使用的 NVIDIA H100s 夠接近，使其成為類似工作負載的可行替代方案。我們在 Microsoft Azure 和兩個英國學術高效能運算（HPC）平台 **Baskerville**$^6$ 和 **Isambard-AI**$^7$ [50] 上進行了實驗，評估了各種配置。此外，我們還利用了 Microsoft Azure 的 AI Foundry，這是一套旨在簡化與基礎模型整合的工具和 API。

**Microsoft Azure**。我們使用了兩台類型為 `8Standard ND96amsr A100 v4` 的虛擬機器，每台提供：
- 96 個 vCPU 和 1800 GB 系統記憶體
- 每個 VM 8 個 NVIDIA A100 80GB GPU

這些 VM 為大型模型微調提供了出色的記憶體利用率。我們發現，每個節點使用 8 個 GPU，特別是兩個節點各有 8 個 GPU（總共 16 個 GPU）來微調 32B 模型，由於更緊密的 GPU 耦合和更好的記憶體飽和度，導致訓練更有效率。相比之下，每個節點只有 4 個 GPU 的 HPC 系統需要在更多節點上進行分散式訓練，例如 Isambard-AI 上的 6 個節點（總共 24 個 GPU），這會引入額外的開銷並降低效率。

透過 Azure AI Foundry，我們存取了以下模型的推理端點：
- OpenAI API 模型：GPT-4o, o3-mini
- DeepSeek 模型：DeepSeek-R1

這些端點實現了推理追蹤和合成使用者查詢的高效生成，以及對前沿 LLM 的最終效能測試。

**Baskerville**。額外的實驗是在 Baskerville 上進行的，這是由伯明翰大學託管的 GPU 集群。每個節點包含：
- 4 個 NVIDIA A100 GPU（40GB 或 80GB），透過 NVLink 3.0 連接
- 節點之間的高頻寬 InfiniBand HDR 互連

我們也可以使用帶有 NVIDIA H100 80GB GPU 的探索性節點，這些節點用於選定的微調和評估運行。

**Isambard-AI Phase 1**。我們還在 Isambard-AI 上進行了實驗，這是英國國家 AI 研究運算平台之一。Isambard-AI 的第一階段由 42 個基於 `arch64` 架構的節點組成。每個節點包括：
- 4 個 NVIDIA GH200 Grace Hopper 超級晶片
- 每個超級晶片結合了一個 Grace CPU 和一個 Hopper H100 GPU
- Slingshot 11 高速互連（每個節點 4 個 Cassini NIC，每個 200 Gbps）

**運算用量總結**。在不同的平台上，我們大約使用了：
- Isambard-AI 上 700 個 GPU 小時
- Baskerville 上 500 個 GPU 小時
- Microsoft Azure 上 2500 個 GPU 小時

這些運算資源使得能夠在模型大小、微調策略和推理配置上進行全面的實驗。最終 32B 參數模型的微調持續了大約 80 個 GPU 小時。

# 3.2 管線概覽

我們的管線包含多個步驟：使用向量資料庫索引一個集合；透過向量相似性檢索文件以回應使用者查詢，對獲得的結果進行推理，最後生成答案。在本節中，我們將介紹管線的每個步驟，從系統的核心部分——所使用的語言模型開始。

# 3.2.1 精簡語言模型

根據先前在測試時間擴展 [3, 7] 方面的研究，我們也採用 **Qwen2.5-Instruct** 模型，因為它們具有全面的競爭效能、擴展的上下文長度和開源可用性。特別是，我們在此重點關注從 1.5B 到 32B 參數範圍的模型，以了解不同規模下模型的能力。在圖 2 中，我們透過遵循 [7] 中描述的相同訓練程序，在不同模型大小上重現了 s1.1* 微調，並檢查了模型在（數學推理）**AIME24** $^{10}$ 基準測試上的效能。

在這種設定中，當採用至少 14B 參數的模型時，推理能力的好處顯而易見，而對於較小的模型（1.5B），微調過程最終會對模型效能產生負面影響。儘管作者也提出了一種預算強制方法來控制測試時間運算，透過強制終止模型的思考過程或在模型試圖結束時附加 "Wait" 來延長其生成，但在這個初步實驗中我們沒有應用它，以便能夠比較不同規模的基線推理能力。

# 3.2.2 檢索系統

如第 2.2 節所述，檢索增強生成（RAG）系統有兩個關鍵組件：**檢索器**和**生成器**。對於我們的檢索器，我們使用基於嵌入的方法，其中文件塊被索引並使用**句子轉換器模型** [51] 給予向量嵌入。為了查詢向量資料庫，執行相似性搜尋以識別前 $k$ 個最相似的塊。

作為預設的嵌入模型，我們採用 `sentence-transformers/all-mpnet-base-v2`。該模型有 1.09 億個參數，並將句子和段落映射到一個 768 維的向量空間。該模型的最大序列長度為 384 個標記。請注意，在將我們的文件分割成塊時，我們預設使用 50 個標記的塊重疊。在實踐中，我們發現這個句子轉換器模型在提供良好效能的同時，也快速且便宜用於推理。

![](https://cdn-mineru.openxlab.org.cn/result/2025-08-24/68b0ebd8-97f1-4de9-8a4f-ac0495ec80bd/0a4fef0d44520d38d906c0072bb20d5648f79781450e1d336ca93f91ea38f3c0.jpg)
圖 2：Qwen2.5-Instruct 模型及其後訓練版本在 AIME24 上的效能，後者是在 DeepSeek-R1 推理追蹤上進行微調的（重現 s1.1 工作，遵循 [7]）。

我們使用 **Chroma** $^{11}$ 向量資料庫，它預設使用 $l^2$-範數相似性分數度量。在我們的程式碼庫中，我們也提供了讓使用者使用替代的句子轉換器模型和選擇使用 **FAISS** [52] 資料庫的選項。在我們的用例中，我們發現 Chroma 和 FAISS 提供了相似的檢索效能，但 Chroma 稍微快一些。

我們的檢索系統使用**完整文件檢索**，如果某個特定文件的任何塊被發現在前 $k$ 個塊集合中，我們的系統將繼續檢索該塊來源的整個原始文件。這確保了 LLM 接收到圍繞相關資訊的完整上下文，即使最初只有一小部分文件被標記為相關。

# 3.2.3 合成資料生成

給定一個文件集合，我們使用一個語言模型來生成一系列查詢，這些查詢是：(a) 與集合中選定的文件相關；(b) 依賴理解文件內容中的資訊以提供有效答案。透過這種方式，我們能夠生成大量使用者請求，並預先知道正確答案（即特定文件和文件中的特定資訊）。為了建立一個具有挑戰性的評估資料集，我們也提示模型產生更複雜的查詢，例如模糊的使用者請求。有關這方面的更多細節將在實驗部分描述的個案研究中給出。

在我們的實驗中，我們依賴 **OpenAI 的 GPT-4o** 來生成一組高品質查詢，以測試我們系統的有用性，但我們的程式碼庫允許使用者自訂他們自己的設定，例如模型的選擇、提示範本和要生成的查詢數量。這樣使用者也可以使用本地 LLM 進行此步驟。

# 3.2.4 推理追蹤

給定一個合成生成的查詢和一組從我們的集合中檢索到的文件，我們提示一個大型推理模型以獲得其**推理追蹤**和最終答案。對於此步驟，我們在實驗中使用了 **DeepSeek-R1**，但使用者可以輕鬆選擇不同的推理模型。透過這個過程，我們生成了一個**推理追蹤資料集**，每個追蹤都包含一個查詢、一組檢索到的文件、推理過程和模型的最終答案。

# 3.2.5 微調

我們使用推理追蹤來**微調一個較小的模型**，以增強其在測試時的能力。目標是模型應該在提供最終答案之前開始產生類似於 DeepSeek-R1 的「推理過程」，並且該推理過程應該能改善整體效能。

我們遵循 s1 [7] 中描述的方法，並對 Qwen2.5-Instruct 模型（範圍從 1.5 到 32B 參數）的下一個標記預測執行**監督式微調**，使用基本的超參數。主要的挑戰，也區分了我們與 s1 的設定，是我們每個模型回應都比 s1 資料集中的長得多，因為它們包含推理追蹤和一組檢索到的文件。這是由於我們檢索的是完整文件而不是像第 3.2.2 節所述的塊。特別是，在我們首次嘗試將檢索到的文件數量設定為 5 來創建推理追蹤時，使用 Qwen2.5 分詞器的訓練範例的平均標記長度為 74641。相比之下，s1K $^{12}$ 和 s1K-1.1 $^{13}$ 資料集的平均標記長度分別為 9109 和 26969。為了在保持相同運算資源的情況下訓練我們的模型，我們採用了**自動文件摘要**，以減少輸入上下文的長度，同時仍能受益於檢索到的材料。

為了在保持相同運算資源的情況下訓練我們的模型，我們採用了**自動文件摘要**，以減少輸入上下文的長度，同時仍能受益於檢索到的材料。

# 3.2.6 檢索文件摘要

為了使訓練過程成為可能，我們透過特別處理我們集合中原始文件的大小來減少上下文的長度，同時保持其核心資訊。我們採用了 **Qwen2.5-32B-Instruct** 來生成我們集合中每個文件的摘要版本，將每個文件的大小減少到其原始長度的 85%。在我們的實驗中，我們還確保這對檢索效能沒有影響，但使用者應評估這在其他應用中是否一致。透過使用摘要文件，我們推理追蹤的平均標記長度減少到 7544。

一種替代基本文件摘要的方法是**查詢感知文件摘要**，即在檢索每個文件後，動態地對其進行摘要。這樣，摘要過程就會知道要保留哪些部分（與使用者查詢相關的部分）以及要從摘要中排除哪些部分。但請注意，這會減慢系統速度，因為對於每個使用者查詢來說，這將是一個額外的 LLM 行動，而我們的情況則是一個靜態的、摘要版本的集合。

# 3.3 對話介面

在接下來的部分，我們將描述如何連接所有這些元素，以實現系統與使用者之間流暢的多輪互動。

# 3.3.1 聊天互動的編排

為了將所有這些組件整合在一起，我們使用 Python 中的 **LangChain** $^{14}$ 框架來開發我們的 RAG 管線，並將其與我們微調的語言模型結合，創建一個對話聊天機器人應用程式。

對於我們的 RAG 應用程式，我們希望允許使用者進行來回對話，其中語言模型獲得先前的對話歷史和檢索到的上下文來建構回應。為了合併歷史訊息，必須使用對話歷史和一個**提示範本**。提示範本將原始的使用者/人類-AI 聊天互動轉換為語言模型可以處理並生成回應的格式。通常，聊天範本是特定於語言模型的，這意味著不同的語言模型系列，如 Llama [41]、Gemma [19, 46] 和 Qwen [17, 53] 使用不同的聊天範本。例如，對於 Qwen2.5-Instruct 模型，使用以下格式來指示給定互動的角色和內容：

`<|im_start|>{role} {content}<|im_end>`

角色可以是 `user`、`assistant` 或 `system` 之一。系統訊息對於指示模型執行某些動作或採用不同特徵（例如使用的語氣或風格）很有用。給定一個使用者-AI 聊天互動列表，我們可以**使用 Qwen 提示範本**來建構一個給語言模型的提示，例如：

`<|im_start|>system 你是一個樂於助人的助手。<|im_end>`
`<|im_start|>user 你好<|im_end>`
`<|im_start|>assistant 你好！我今天能幫你什麼忙嗎？<|im_end>`

為了向模型呈現從知識庫中檢索到的上下文，我們可以建構一個**系統提示範本**（參見附錄 A.1 中我們用於第 4 節描述的示例應用的系統提示），該範本定義了模型的任務，並呈現了檢索到的上下文以及額外資訊，例如使用者的背景。

請注意，我們也可以使用**使用者提示範本**，其中檢索到的上下文呈現在使用者訊息中。我們選擇不這樣做是為了限制對話歷史上下文長度的增長，因為在使用者訊息中呈現檢索到的上下文會導致隨著聊天的發展，檢索到的上下文保留在對話歷史中。在我們的案例中，當使用檢索時，檢索到的上下文會以系統提示的形式提供給模型，因此它可以在整個對話中有所不同。

此處使用的語言模型都具有有限的上下文視窗。因此，隨著對話累積長訊息歷史，可能需要**減少聊天歷史的大小**。我們透過根據標記計數來修剪歷史來實現這一點。請注意，我們從不從歷史中刪除系統提示，並且只在必要時刪除最舊的聊天互動。

# 3.3.2 檢索作為工具

在標準的 RAG 設定中，我們可能只需將最後一則使用者訊息作為檢索器的查詢。然而，這種簡單方法有兩個關鍵問題：

首先，在許多對話互動中，使用者訊息本身不足以作為檢索器的有用查詢。這種情況的常見情況是基於先前對話歷史的**後續問題**。例如，考慮以下對話：

**使用者**：我最近一直頭痛，有哪些常見方法可以緩解頭痛？
**AI**：緩解緊張性頭痛的常見方法包括服用非處方止痛藥，如布洛芬或對乙醯氨基酚，在頭部或頸部敷上溫熱或冰冷的敷布，以及練習放鬆技巧。
**使用者**：我在哪裡可以買到它們？

在標準的 RAG 設定中，如果沒有完整的對話上下文，查詢「我在哪裡可以買到它們？」是模糊不清的。

其次，通常使用者訊息可能足夠簡單，以至於模型不需要檢索。例如，對於「你好」這樣簡單的使用者訊息，避免檢索並讓模型直接回應會更便宜。

為了解決這兩個問題，可以將檢索視為模型可以存取的一個**工具**。就我們的目的而言，一個工具是一個函式與其模式的關聯，該模式定義了函式的名稱、描述和引數。然後，這個模式被傳遞給語言模型，而語言模型可以透過定義要使用的工具名稱和要使用的引數來決定使用該工具。這種方法利用了**工具呼叫**$^{15}$（有時稱為函式呼叫），現在許多現代聊天模型和端點提供者都普遍支援這種功能。

在這種設定中，我們將語言模型稱為**代理** [20, 54]，它將語言生成與行動相結合。通常，代理指任何可以感知其環境並對該環境採取行動的東西 [55]。代理可以執行的行動集由它可以存取的工具定義。對於我們的 RAG 管線，語言模型可以被視為一個代理，而工具就是**文本檢索器**。因此，對於給定的使用者訊息，模型可以決定查詢檢索器或直接用自然語言回應。

請注意，在我們的用例中，語言模型理想情況下只在簡單的使用者訊息中決定不使用檢索，因為我們希望大多數模型回應都以知識庫中的資料為基礎。在語言模型決定使用檢索器的情況下，它會進行工具呼叫，並根據聊天歷史決定要使用的查詢。因為語言模型可以存取對話歷史，所以它可以利用先前的聊天互動來為向量資料庫選擇一個相關的查詢。

圖 3 呈現了給定查詢的完整流程。首先，查詢被呈現給一個對話代理語言模型，該模型決定是查詢檢索器，還是直接回應（在簡單訊息的情況下）。這個對話代理的系統提示在附錄 A.2 中呈現。如果對話代理決定對檢索器執行工具呼叫，它會根據聊天歷史為檢索器編寫一個查詢，並從知識庫中檢索相關的文件塊。最後，我們如上所述，透過推理模型的系統提示向模型呈現檢索到的上下文，以根據聊天歷史生成回應。請注意，在不同階段選擇語言模型具有靈活性，因為決定是先檢索再回應還是直接回應的對話代理語言模型，可以與使用檢索到的上下文生成回應的語言模型不同。在我們的最終模型中，我們使用 Qwen2.5-Instruct-32B 作為對話代理語言模型，t0-1.1-k5-32B 作為 RAG 語言模型，因為我們發現 Qwen2.5-Instruct-32B 在工具呼叫方面更為一致。

![](https://cdn-mineru.openxlab.org.cn/result/2025-08-24/ae50e284-f0e7-4cc1-9bbc-e953bbb60c71/60b99cd40979d50e07f28f82564d225397c1f35583b0282c0148ac6e5f25175b.jpg)
圖 3：對話式檢索增強生成管線。

# 3.3.3 前端介面

這個管線的最後一段程式碼是前端：一個以 Svelte 框架編寫的靜態網頁應用程式 $^{16}$，它允許使用者在一個與 OpenAI 的 **ChatGPT** 網站極為相似的介面中與語言模型進行對話。該網站部署在 GitHub Pages $^{17}$，並透過 REST API 與 Python 聊天機器人（後端）互動。使用者可以創建多個單獨的對話執行緒，每個都有唯一的識別碼，並隨時切換。聊天機器人的回應由瀏覽器解析：預設情況下，只有主要答案會完整顯示給使用者，推理追蹤則可透過下拉式切換開關獲得。

一般來說，後端負有儲存對話歷史的唯一責任：前端僅作為解析和向終端使用者顯示此資訊的方式。因此，前端的狀態完全源自後端；這種設計防止了如果前端儲存自己的對話歷史副本可能出現的潛在不一致性。

因為 Python 聊天機器人透過 HTTP 暴露，而現代瀏覽器不（預設）允許 HTTPS 頁面向 HTTP 端點發出請求，因此有必要設置一個 Nginx 反向代理作為中介。因此，不安全的 HTTP 連接由代理處理，而網站只會看到對安全 HTTPS URL 的連接。如果需要，這可以替換為 Caddy $^{18}$。

對於這個概念驗證，實施身份驗證以將每個對話唯一地與使用者關聯被認為是不必要的。因此，網頁的每個訪客都可以看到每個可用的對話。使用 OAuth2 實施身份驗證將是更嚴肅部署的一個明顯的後續步驟。

# 4 示範應用

測試時間擴展和推理的研究通常將其應用重點放在數學和程式碼領域 [3, 6, 7]，因為處理此類問題可能需要推理過程，評估最終答案的正確性是直截了當的，並且有許多可用的資料集 [56]。

在我們的實驗中，我們轉而專注於一個不同的場景，這有望更接近於旨在利用資訊檢索和推理結合來進行決策的實際應用。我們考量由 NHS A-to-Z 狀況網站提供的知識體系 $^{19}$。對於列出的將近 1000 種狀況中的每一種，一個網頁提供有關它的資訊以及一系列可能的下一步行動，具體取決於患者的症狀（例如尋求緊急 GP 預約或直接去 A&E）。我們認為這是一個有趣的設定來測試我們的模型，因為它將需要一個檢索組件（來解釋使用者查詢並在可用文件中搜尋）和一個推理元素（來解釋患者症狀並決定最佳的下一步，同時保持以提供的資訊為基礎）。整個過程的概覽，我們將在本節中逐步介紹，如圖 4 所示。

需要強調的是，此處呈現的原型並非旨在作為提供醫療建議的工具。相反，醫療領域純粹被用作其在依賴私人、專業知識和複雜查詢來支援決策的跨行業潛在適用性的示範。

# 4.1 資料集

我們透過爬取 NHS 狀況子網域下的所有網頁來收集狀況，獲得了 990 種不同的狀況 $^{20}$。然後我們移除了「心理健康」這個狀況，因為該頁面實際上是一個狀況集合，其結構與其餘集合不同。剩下的 989 個被組織在一個單一的資料集（作為 JSON Lines 文件）中，包含狀況名稱（頁面標題）、頁面的全部內容（如果狀況網頁包含多個子頁面，我們將內容連接成一個單一的文本流）和使用 Qwen2.5-32B-Instruct 獲得的頁面內容摘要版本。用於此任務的提示可在附錄 A.3 中找到。

使用此提示，我們將每個文件的大小減少到其原始長度的 85%，同時保留了與任務相關的核心資訊，因為每個頁面都包含樣板文本和重複資訊。然而，如此大幅度地減少內容大小確實可能導致下游任務中出現檢索問題，因此我們比較了在完整內容或僅在摘要版本上操作時的檢索效能（參見表 1）。

# 4.2 合成使用者查詢

給定一個狀況頁面的完整內容和一個預定的處置（自我照護、緊急初級照護和 A&E），我們提示 GPT-4o 生成一個**合成生成的患者查詢**（或在我們的請求不適用時拒絕，例如，處置與頁面內容中可能的結果不一致）。我們還要求模型生成**一般患者資訊**（例如年齡、職業和社會支持），以與狀況和處置保持一致。我們控制患者性別，因為在早期實驗中我們注意到模型過度生成女性患者的範例，而非男性。為了更好地理解我們的方法在更複雜的請求下會如何失敗，我們要求模型生成三種類型的查詢：

* **基本**：基於單一狀況頁面，查詢提到相關症狀。
* **疑病**：基於單一狀況頁面，查詢提到相關症狀以及其他不相關的抱怨和過度的焦慮表現。
* **輕描淡寫**：基於單一狀況頁面，查詢輕描淡寫了症狀的嚴重程度。

雖然**基本**代表這類系統最常見的請求類型，但**疑病**和**輕描淡寫**透過提供過多或過少關於狀況和嚴重程度的資訊來挑戰管線。

用於生成合成資料的提示可在附錄 A.4 中找到。作為一個例子，以下合成請求是從一個基本查詢的輸入提示生成的，該查詢來自一位女性，應與**髖關節置換**這個狀況相匹配，並且處置應為**緊急初級照護**。範例中的其餘內容由 GPT-4o 生成：

* **範例**

* **一般患者資訊**：年齡：65歲，性別：女性，職業：退休教師，社會支持：我與丈夫同住，他幫我做家務。醫療史：我患有骨關節炎，偶爾服用非處方止痛藥。沒有其他重大病症。

* **症狀描述**：我大約兩週前做了髖關節置換手術，最初一切似乎都很好，但現在我注意到一些令人擔憂的症狀。我髖關節周圍的區域腫脹發紅，並且比以前感覺更嫩。我還有點發冷，當我檢查時，今天早上我的體溫大約是 38.5°C。當我試著走路時，我感覺腿部疼痛稍微增加。我沒有看到傷口流膿，但我擔心這可能是感染的開始。我應該緊急檢查一下嗎？

使用上述過程，我們生成了兩個資料集，一個包含 1000 個合成查詢作為評估集，另一個包含 2000 個合成查詢作為用於微調的資料集。為了確保我們的評估集和微調集之間沒有重疊，我們確定了具有相同狀況和處置組合的查詢。然後我們從微調資料集中刪除了這些查詢，並生成了更多資料，使我們的查詢總數恢復到 2000。一位臨床醫生審查了我們合成生成請求的一個子集，確認了它們的適用性和不同複雜性等級。我們在這個步驟依賴於一個前沿 LLM（GPT-4o）；如果要在安全環境中處理私人資料，我們的方法的這部分將需要不同的策略。作為替代方案，我們建議以下選項：如果可能，獲得有關所研究知識體系的真實查詢範例，這將完美地反映需要自動化的過程類型。或者，我們建議採用一個可以在本地運行的精簡模型，如 Qwen2.5-32B-Instruct，然後遵循我們其餘的合成資料生成方法。在這種情況下，仔細評估合成資料的品質對於確保其對下游任務的有效性至關重要。

# 4.3 檢索效能

使用 1000 個合成使用者查詢的評估集，我們在表 1 中報告了我們的檢索組件在索引完整狀況頁面或摘要版本時的效能。正如在系統設定概述中所述，當索引完整文件時，這些文件被分割成塊，以允許識別狀況頁面中與查詢相關的特定段落。分塊將資料庫中的文件數量從 988 個增加到 5824 個。我們在測試檢索系統時考慮了一系列截止點 $k$，範圍從 $k = 1$（只返回向量資料庫中最相似的文件）到 $k = 100$。

指標 $p@k$ 指的是查詢中正確狀況出現在 $k$ 個返回文件中的分數 $p$。例如，$p@5$ 是正確狀況出現在檢索到的五個最相似文件中的查詢比例。請注意，當檢索摘要時，截止數字對應於狀況頁面的數量，因為摘要文件的上下文長度都小於我們的嵌入模型（384），而對於完整文件，它對應於返回的塊數。

了解不同截止點的效能使我們能夠選擇一個合適的檢索文件數量，以便在結合檢索和推理時使用。更多的文件將在大多數情況下保證檢索到正確的狀況，但也會導致下游 LLM 的上下文更長，影響微調和推理。

表 1：在索引完整頁面（然後分割成塊）與相同頁面的摘要時，不同截止點的檢索準確度。

| 輸入 | 文件數 | p@1 | p@5 | p@10 | p@30 | p@50 | p@100 |
| :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- |
| 完整頁面 | 5 824 | 0.47 | 0.68 | 0.78 | 0.87 | 0.91 | 0.94 |
| 摘要 | 989 | 0.51 | 0.76 | 0.83 | 0.93 | 0.96 | 0.98 |

鑑於表 1 所示的效能，在我們接下來的實驗中，我們考量索引文件的摘要，因為這始終能帶來更高的檢索效能。請注意，對於我們選擇的用例，我們知道系統將接收到什麼類型的查詢，因此我們以保留該資訊的方式對內容進行了摘要。對於一個不只專注於確定狀況和處置的更通用檢索系統，索引完整頁面可能更為明智。關於截止點，我們最初實驗了 $k = 5$ 和 $k = 30$，這分別在 76% 和 93% 的查詢中檢索到正確的狀況。關於微調過程和下面詳述的最終實驗，我們使用 $k = 5$ 個檢索文件，因為這在我們的資源限制下產生了一個可管理的上下文長度，並且更容易透過使用者介面進行探索。然而，請注意，這個選擇施加了一個最大可達到的預測準確度為 76%，因為推理器只將檢索到的文件視為潛在相關的。為了在保持簡短的檢索文件清單的同時解決這個限制，我們探索了幾種策略，包括透過額外的 LLM 呼叫重新排序結果（類似於 [57]）和重新措辭使用者查詢，靈感來自 ReAct 框架的推理和行動方法 [20]。然而，這些替代方案在我們的設定中並未持續帶來顯著改進。

# 4.4 微調過程

對於我們 2000 個範例資料集中的每個合成查詢，我們使用 $k = 5$ 作為檢索截止點，提示 DeepSeek-R1，並提供描述潛在相關狀況的摘要內容。用於生成推理追蹤的提示範本可在附錄 A.5 中找到。透過這個過程，每個查詢的結構如下：

-   五個檢索到的（摘要）狀況頁面；
-   來自 DeepSeek-R1 的推理過程，以根據它們確定正確的狀況和處置；
-   模型提供的最終答案。

這些組件都被連接成每個查詢的一個單一文本流，以便然後對一系列小型版本的 Qwen2.5-Instruct 模型進行下一個標記預測的監督式微調。我們期望看到的是，模型將在提供最終答案之前開始產生類似於 DeepSeek-R1 的「思考」或推理過程，並且該推理過程應該能改善整體效能。

微調參數是根據 [7] 的建議選擇的。最重要的配置選擇如下：

* **Epochs**：5
* **學習率**：$10^{-5}$，帶有餘弦調度器
* **批次大小**：1（每台裝置）
* **精度**：bf1oat16 (bf16)
* **區塊大小**：32768
* **分片**：FSDP（full_shard auto_wrap）
* **梯度檢查點**：啟用
* **優化器**：Adam，權重衰減為 $10^{-4}$，$\beta_{1} = 0.9$，$\beta_{2} = 0.95$
* **評估頻率**：每 50 步

所有模型都使用上述相同的微調參數進行訓練。由於可用性和成本考量，GPU 和系統配置有所不同。訓練設定如下：

* **1.5B, 3B, 7B 模型**：Baskerville 上 $4 \times \text{A100 80 GB}$ GPU（1 個節點）
* **14B 模型**：Baskerville 上 $16 \times \text{A100 80 GB}$ GPU（4 個節點）
* **32B 模型**：Azure 上 $16 \times \text{A100 80 GB}$ GPU（2 個 VM）

# 4.5 狀況和下一步行動預測

在本節中，我們測量檢索增強型推理是否改善了精簡語言模型的效能。在表 2 中，我們報告了我們的 32B 參數微調模型（命名為 t0-1.1-k5-32B）在兩個任務上的效能：(i) 給定症狀的文本描述，確定合成患者的狀況；(ii) 在文件內容中建議的選項中，確定下一步的行動方案。我們假設一個基線非推理模型（Qwen2.5-32B-Instruct）已經具備一些一般知識，能夠在一個不錯的水平上執行此類任務。然而，檢索和推理能力的整合應該會改善效能，因為模型將額外獲得領域內的證據。用於評估模型在預測狀況和合適的下一步行動上的效能的提示範本在附錄 A.6 中給出。為了與其他系統進行比較，我們報告了兩個近期可比較的精簡推理模型 s1.1-32B [7] 和 Qwen3-32B [53] 的效能，以及一系列最先進的大型語言模型（GPT-4o、o3-mini、DeepSeek-R1）的效能，以了解整體前沿效能。對於 t0-1.1-k5-32B 和 s1.1-32B，我們使用預算強制來控制測試時間的運算，如 [7] 中所述 $^{21}$。

如表 2 所示，一個 32B 參數模型已經具備了手頭主題的一些核心知識，因為它能夠在 38% 的情況下從合成患者描述中識別出正確的狀況，並在 46% 的時間內預測出正確的下一步行動方案。這種起點評估對於確定所採用語言模型的初始能力是必要的。根據所考慮的任務和知識領域，效能會有所不同，特別是當應用程式專注於一個不廣泛可用的特定知識體系時，例如僅在組織內部網路上共享的材料。作為比較，一個前沿非推理模型，如 GPT-4o，在狀況準確度方面從 49% 開始，處置準確度為 56%。

提供檢索到的文件有助於模型更好地預測這兩個任務，對於相對較小的 Qwen2.5-32B，狀況準確度提高了超過 15%，對於 GPT-4o 則提高了 7%。Qwen 在處置準確度方面也獲得了 4 個百分點的提升，而 GPT-4o 的效能則略有下降，這可能是由於現在可用的資訊量增加了更多歧義。對於所檢驗的兩個前沿推理模型（o3-mini 和 DeepSeek-R1），狀況準確度也觀察到大幅提升，這凸顯了整合檢索組件以向模型提供相關領域內證據的巨大好處。

轉向所檢驗的精簡模型，我們可以看到在提供最終答案之前整合思考過程的額外好處。我們的 t0-1.1-k5-32B 模型，已經在領域內推理範例上進行了微調，進一步提高了確定正確狀況的準確度，與基礎 Qwen 模型相比，效能提高了近 20%，並且相對於僅使用檢索，還有額外的小幅提升。狀況準確度的結果優於所檢驗的其他精簡推理解決方案（s1.1-32B 和新發布的 Qwen3-32B），使該模型達到與 o3-mini 和 DeepSeek-R1 等大型前沿推理模型相同的水平。

我們沒有看到確定處置方面有類似的顯著改進。儘管該模型的效能優於基礎的 Qwen2.5-Instruct-32B 和通用型精簡推理模型，但它並未達到 o3-mini 等前沿模型的效能。我們認為這是由於 DeepSeek-R1 提供的推理追蹤，它設定了可以蒸餾到小型模型中的專業知識的限制，相較於 o3-mini 在處置方面的更好推理過程。同樣重要的是要注意，o3-mini 在沒有檢索到的文件提示下，狀況準確度非常低。從檢查輸出中可以看出，o3-mini 在沒有支援證據的情況下做出預測時似乎會失去焦點，最終會考慮太多可能的場景。

這個評估的主要結果是，一個檢索增強型精簡推理器模型可以在 76% 的情況下將正確的狀況列入幾個選項中（如表 1 所示），並在 56% 的情況下預測出正確的狀況，這與最先進的前沿模型相當（如表 2 所示）。這在與使用者開始對話之前是一個強有力的起點，這將允許模型收集額外資訊、擴展其在資料庫中的搜尋，並更準確地縮小可能的狀況和患者處置（參見圖 6 中的對話介面範例）。

表 2：LLM 和 $k$ 值在狀況和處置方面的準確度。我們首先報告所檢驗的精簡語言模型，然後是一系列前沿大型語言模型。一個破折號（-）表示 $k$ 值為零：也就是說，作為基線，模型沒有提供任何檢索到的上下文。請注意，對於所有依賴檢索組件的模型，其狀況可達到的最大準確度為 0.76，如表 1 所述。所有報告的值均為 10 次運行的平均準確度。標準差始終在 0.01 左右，為了清晰起見已省略。

| LLM | k | 狀況 | 處置 |
| :--- | :--- | :--- | :--- |
| **精簡語言模型** | | | |
| Qwen2.5-32B-Instruct | - | 0.38 | 0.46 |
| | 5 | 0.54 | 0.50 |
| t0-1.1-k5-32B | 5 | 0.56 | 0.51 |
| s1.1-32B | 5 | 0.49 | 0.46 |
| Qwen3-32B | 5 | 0.53 | 0.48 |
| **前沿語言模型** | | | |
| GPT-4o | - | 0.49 | 0.56 |
| | 5 | 0.56 | 0.54 |
| o3-mini | - | 0.27 | 0.54 |
| | 5 | 0.57 | 0.56 |
| DeepSeek-R1 | - | 0.44 | 0.53 |
| | 5 | 0.56 | 0.51 |

# 5 討論

在本節中，我們將介紹三個方面，這些方面應有助於指導基於我們技術報告的未來實施。我們首先涵蓋通用與特定領域推理之間的權衡，然後我們檢查如何進一步減小模型大小，最後我們概述了我們系統前端作為一個原型，可直接在我們的 GitHub 儲存庫中獲得。

# 5.1 通用與特定領域推理器

我們技術工作中的主要基礎設施複雜性是微調一個 32B 參數模型，以使用來自更大前沿模型的推理追蹤來增強其領域內推理過程。或者，我們本可以採用一個相同大小的更通用推理模型，例如 s1.1。在表 2 中，我們強調了我們方法的整體更佳效能，在本節中，我們透過考量所測試的各種查詢來深入比較。

在表 3 中，我們看到在**基本**類型的查詢上，我們的模型在 52% 的情況下準確識別出正確的狀況，並在 64% 的情況下準確識別出正確的處置，甚至在與使用者開始對話之前。對於確定正確狀況，**疑病**查詢的效能提高到 62%，因為增加了更多額外細節，然而在這種情況下和**輕描淡寫**查詢中，處置的效能都下降到 45% 左右，正是因為它們被設計來挑戰模型。與我們的模型相比，一個通用型推理模型，如 s1.1，效能要差 3% 到 12%，具體取決於查詢類型和評估指標。此外，在分析錯誤類型時，我們觀察到在使用 s1.1 而非 t0-1.1-k5-32B 處理基本查詢時，低估錯誤增加了超過 40%——例如預測「緊急初級照護」而不是正確的「A&E」。

總體而言，擁有一個經過訓練的精簡推理模型，其推理追蹤顯示如何處理與所研究領域相關的決策，與更通用型的推理器相比，帶來了明顯的優勢。雖然訓練此類領域內模型所需的追蹤數量並不過多（s1 研究採用了 1000 個追蹤，而我們使用了 2000 個），但在專注於私人或敏感資料集合的應用中獲取它們仍然是一個挑戰。為了解決這個問題，可以考慮以下幾種策略：

* 根據一組給定的查詢和檢索到的文件手動創建推理追蹤；
* 在本地或私人基礎設施上託管和查詢一個通用型推理模型，並手動更正其回應以生成所需的追蹤；
* 採用一個通用型推理器，並在本地或私人基礎設施上進一步微調它（這可能需要更少的追蹤）。

雖然這些選項比依賴一個前沿推理模型更複雜，但它們並不構成在安全環境或敏感資料上採用精簡檢索增強型推理模型的根本障礙。

# 5.2 蒸餾以進一步減小模型大小

在我們的工作中，我們遵循了 s1 團隊 [7] 最近提出的策略，將推理能力從 DeepSeek-R1 等前沿模型蒸餾到一個相對較小的模型，例如我們的 32B 參數解決方案。雖然我們的模型在任務上優於所有其他精簡方法，如表 2 和表 3 所討論，但它仍然需要大約 64GB 的 GPU 記憶體才能以 16 位精度載入模型。由於對於使用資源受限的安全環境的團隊來說，這種要求並非總是輕而易舉可得，我們在本節中探討是否可以進一步減小模型大小而不會顯著影響整體效能。透過蒸餾來增強小型語言模型推理能力的可能性是 [6] 的主要貢獻之一。然而如圖 2 所示，根據任務的不同，模型只會在達到某個大小後才開始超越其非推理基線。以類似的方式，我們評估了從 1.5B 到 32B 參數的蒸餾模型的效能，其中最小的模型只需要 3 到 6 GB 的 GPU 記憶體，使其適合在大多數現代筆記型電腦上執行 $^{22}$。

表 4：不同模型大小的狀況和處置準確度，檢索了 5 個文件。我們還報告了 32B 非推理基線（Qwen2.5-32B-Instruct）和推理能力從中蒸餾出來的前沿模型（DeepSeek-R1）的效能作為參考，檢索了相同數量的文件。

| 模型大小 | 記憶體 (GB) | 狀況 | 處置 |
| :--- | :--- | :--- | :--- |
| 1.5B | 3 | 0.53 | 0.47 |
| 3B | 6 | 0.56 | 0.48 |
| 7B | 14 | 0.54 | 0.48 |
| 14B | 28 | 0.56 | 0.48 |
| 32B | 64 | 0.56 | 0.51 |
| 32B (Qwen 基線) | 64 | 0.54 | 0.50 |
| 671B (DeepSeek-R1) | 1 342 | 0.56 | 0.51 |

如表 4 所示 $^{23}$，將推理能力蒸餾到較小的模型是可行的：即使是 1.5B 參數的模型，其效能也與 32B 參數的非推理模型相當，尤其是在狀況預測方面，並且有效地從其 671B 參數的前沿**「教師」**那裡學習。為了更好地理解 RAG 和推理的組合在不同模型大小下提供的效能提升，我們在圖 5 中比較了每個初始 Qwen2.5-Instruct 模型、帶有 RAG 的相同模型以及結合了 RAG 和推理的後訓練 t0 版本的狀況預測效能。該圖突出了一個對於許多下游應用來說重要的見解：對於一個 32B 參數的模型，主要的效能增益來自於模型解釋檢索到的資訊的核心能力，而對於更精簡的模型（1.5B 和 3B），一個大的效能提升來自於領域內推理訓練，這提供了原本缺乏的解釋能力 $^{24}$。事實上，這種小型檢索增強型推理模型可以提供與比它們大十倍以上的模型相當的效能，這顯著拓寬了部署場景的範圍。這些模型輕巧到可以在許多消費級筆記型電腦上運行，使其在研究和政府應用中得到廣泛應用。

![](https://cdn-mineru.openxlab.org.cn/result/2025-08-24/ae50e284-f0e7-4cc1-9bbc-e953bbb60c71/c09084442f92a36dd3fc3f480714834a7d00eaba9a48bcd7647ad90bb5e71a3c.jpg)
圖 5：Qwen2.5-Instruct 模型單獨、使用 RAG 和結合了 RAG 和推理的後訓練 t0 版本的狀況預測效能。

正如我們的報告中廣泛討論的，如果其他團隊想要追求這一點，設定一個明確的基準來進行所需任務是至關重要的，以了解 (i) 與基礎模型相比，檢索和推理的結合是否可以改善效能並減少幻覺和其他類型的錯誤，以及 (ii) 模型大小和效能之間的最佳權衡是什麼，因為根據應用程式的不同，一個更精簡的解決方案仍然可以提供可靠的效能，同時非常顯著地減少運算需求和成本。

# 5.3 前端介面

在 GitHub 儲存庫中，我們提供了一個簡單的前端介面，以了解我們的 t0-1.1-k5-32B 模型如何在實踐中使用，作為處理模型編排和多輪聊天互動的更大系統的一部分。在圖 6 呈現的介面快照中，主要組件被呈現：給定一個使用者查詢（我們合成生成的範例之一），Qwen2.5-Instruct-32B 決定調用檢索器，後者收集 5 個相關狀況（髖部疼痛、髖部骨折等）。然後，t0-1.1-k5-32B 根據查詢和提供的文件生成一個推理過程（在快照中使用下拉菜單顯示），然後回答使用者，建議三種可能的處置之一（自我照護、緊急初級照護，或在本例中為 A&E） $^{25}$。該網頁前端還包括一個用於輸入與查詢相關的人口統計資訊的表單。

所提供的前端可以無縫地適應許多其他應用程式，這些應用程式將依賴於在文件集合上結合模型編排、推理能力和檢索（並可能添加額外的元資料）。

# 6 結論

在本技術報告中，我們描述了如何有效地將推理和檢索增強生成結合到一個單一的精簡模型中。為了展示其在特定領域集合上進行決策的實用性，我們提供了一個案例研究，使用 NHS A-to-Z 集合作為知識體系，來確定一系列合成請求的狀況和處置。我們的模型表現與前沿推理模型相當，尤其是優於其他在數學推理上訓練過但未針對特定領域應用進行微調的小型推理模型。最後，我們強調可以透過將推理能力蒸餾到非常小的模型中來進一步減小模型大小，同時保持強勁的效能。我們希望我們的概述和配套的 GitHub 程式碼庫對於其他對在特定領域設定中結合推理和檢索能力感興趣的人會有所幫助。

# 致謝

RC、FN 和 TL 對這項工作做出了同等貢獻，分別主導了實施（RC）、整體專案（FN）和運算工作（TL）。根據 CRediT 分類法，所有作者的貢獻如下：概念化 (AD, JG, FN)、實施 (RC, TL, FN, RW, PY)、運算基礎設施 (RC, TL, RW)、資料整理 (RC, JG, FN, RW)、前端介面 (PY)、原始草稿 (RC, FN, TL)、審閱與編輯（全體）、顧問 (AD, JG, MG, LT)、專案管理 (AD, JG, FN)。

這項工作由 The Alan Turing Institute 資助。我們要感謝 Christopher Banerji、Maya Bronfeld、Jonathan Carter、Tom Jeffery 和 Giles Lawrence 在整個專案過程中提供的寶貴支持和建設性反饋。

報告中描述的運算部分使用了 Baskerville $^{26}$ Tier 2 HPC 服務。Baskerville 由 EPSRC 和 UKRI 透過 World Class Labs 計劃 (EP/T022221/1) 和數位研究基礎設施計劃 (EP/W032244/1) 資助，並由伯明罕大學的高級研究運算中心運營。

作者還要感謝使用了由 Isambard-AI National AI Research Resource (AIRR) 提供的資源。Isambard-AI 由布里斯托大學運營，並由英國政府的科學、創新與技術部 (DST) 透過英國研究與創新 (UKRI) 和科學與技術設施委員會 [ST/AIRR/I-A-I/1023] 資助。

# 參考文獻

[1] Aaron Jaech, Adam Kalai, Adam Lerer, Adam Richardson, Ahmed El- Kishky, Aiden Low, Alec Helyar, Aleksander Madry, Alex Beutel, Alex Carney, et al. OpenAI o1 System Card. arXiv preprint arXiv:2412.16720, 2024. [2] Charlie Snell, Jaehoon Lee, Kelvin Xu, and Aviral Kumar. Scaling LLM Test- Time Compute Optimally can be More Effective than Scaling Model Parameters. In The Thirteenth International Conference on Learning Representations, 2025. [3] Yuxin Zuo, Kaiyan Zhang, Shang Qu, Li Sheng, Xuekai Zhu, Biqing Qi, Youbang Sun, Ganqu Cui, Ning Ding, and Bowen Zhou. TTRL: Test- Time Reinforcement Learning. arXiv preprint arXiv:2504.16084, 2025.[4] Runze Liu, Junqi Gao, Jian Zhao, Kaiyan Zhang, Xiu Li, Biqing Qi, Wanli Ouyang, and Bowen Zhou. Can 1B LLM Surpass 405B LLM? Rethinking Compute- Optimal Test- Time Scaling. arXiv preprint arXiv:2502.06703, 2025.

[5] Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Quoc V Le, Denny Zhou, et al. Chain- of- Thought Prompting Elicits Reasoning in Large Language Models. Advances in Neural Information Processing Systems, 35:24824- 24837, 2022.

[6] Daya Guo, Dejian Yang, Haowei Zhang, Junxiao Song, Ruoyu Zhang, Runxin Xu, Qihao Zhu, Shirong Ma, Peiyi Wang, Xiao Bi, et al. DeepSeek- R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning. arXiv preprint arXiv:2501.12948, 2025.

[7] Niklas Muennighoff, Zitong Yang, Weijia Shi, Xiang Lisa Li, Li Fei- Fei, Hannaneh Hajishirzi, Luke Zettlemoyer, Percy Liang, Emmanuel Candes, and Tatsunori Hashimoto. s1: Simple test- time scaling. arXiv preprint arXiv:2501.19393, 2025.

[8] Ahmed El- Kishky, Daniel Selsam, Francis Song, Giambattista Parascandolo, Hongyu Ren, Hunter Lightman, Hyung Won Chung, Ilge Akkaya, Ilya Sutskever, Jason Wei, et al. OpenAI. Learning to reason with LLMs. OpenAI, 2024.

[9] Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal, Heinrich Kuttler, Mike Lewis, Wen- tau Yih, Tim Rocktaschel, et al. Retrieval- Augmented Generation for Knowledge- Intensive NLP Tasks. Advances in Neural Information Processing Systems, 33:9459- 9474, 2020.

[10] Yunfan Gao, Yun Xiong, Xinyu Gao, Kangxiang Jia, Jinliu Pan, Yuxi Bi, Yixin Dai, Jiawei Sun, Haofen Wang, and Haofen Wang. Retrieval- Augmented Generation for Large Language Models: A Survey. arXiv preprint arXiv:2312.10997, 2(1), 2023.

[11] Wenqi Fan, Yujuan Ding, Liangbo Ning, Shijie Wang, Hengyun Li, Dawei Yin, Tat- Seng Chua, and Qing Li. A Survey on RAG Meeting LLMs: Towards Retrieval- Augmented Large Language Models. In Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining, pages 6491- 6501, 2024.

[12] Ori Ram, Yoav Levine, Itay Dalmedigos, Dor Muhlgay, Amnon Shashua, Kevin Leyton- Brown, and Yoav Shoham. In- Context Retrieval- Augmented Language Models. Transactions of the Association for Computational Linguistics, 11:1316- 1331, 2023.

[13] Akari Asai, Zexuan Zhong, Danqi Chen, Pang Wei Koh, Luke Zettlemoyer, Hannaneh Hajishirzi, and Wen- tau Yih. Reliable, Adaptable, and Attributable Language Models with Retrieval. arXiv preprint arXiv:2403.03187, 2024.

[14] Anthropic. Building Effective Agents. Anthropic Blog, 2024.

[15] Lei Wang, Chen Ma, Xueyang Feng, Zeyu Zhang, Hao Yang, Jingsen Zhang, Zhiyuan Chen, Jiahai Tang, Xu Chen, Yankai Lin, et al. A Survey on Large Language Model based Autonomous Agents. Frontiers of Computer Science, 18(6):186345, 2024.

[16] Zhiheng Xi, Wenxiang Chen, Xin Guo, Wei He, Yiwen Ding, Boyang Hong, Ming Zhang, Junhe Wang, Senjie Jin, Enyu Zhou, et al. The Rise and Potential of Large Language Model Based Agents: A Survey. Science China Information Sciences, 68(2):121101, 2025.

[17] Jinze Bai, Shuai Bai, Yunfei Chu, Zeyu Cui, Kai Dang, Xiaodong Deng, Yang Fan, Wenbin Ge, Yu Han, Fei Huang, et al. Qwen Technical Report. arXiv preprint arXiv:2309.16609, 2023.

[18] Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie- Anne Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal Azhar, et al. LLaMA: Open and Efficient Foundation Language Models. arXiv preprint arXiv:2302.13971, 2023.

[19] Gemma Team, Thomas Mesnard, Cassidy Hardin, Robert Dadashi, Surya Bhupatiraju, Shreya Pathak, Laurent Sifre, Morgane Rivière, Mihir Sanjay Kale, Juliette Love, et al. Gemma: Open Models Based on Gemini Research and Technology. arXiv preprint arXiv:2403.08295, 2024.

[20] Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik Narasimhan, and Yuan Cao. ReAct: Synergizing Reasoning and Acting in Language Models. In The Eleventh International Conference on Learning Representations, 2023.

[21] Weijia Shi, Sewon Min, Michihiro Yasunaga, Minjoon Seo, Richard James, Mike Lewis, Luke Zettlemoyer, and Wen- tau Yih. REPLUG: Retrieval- augmented black- box language models. In Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers), pages 8371- 8384. Association for Computational Linguistics, 2024.

[22] Charles Packer, Vivian Fang, Shishir G Patil, Kevin Lin, Sarah Wooders, and Joseph E Gonzalez. MemGPT: Towards LLMs as Operating Systems. CoRR, 2023.

[23] Xinyun Chen, Renat Aksitov, Uri Alon, Jie Ren, Kefan Xiao, Pengcheng Yin, Sushant Prakash, Charles Sutton, Xuezhi Wang, and Denny Zhou. Universal Self- Consistency for Large Language Model Generation. arXiv preprint arXiv:2311.17311, 2023.

[24] Bradley Brown, Jordan Juravsky, Ryan Ehrlich, Ronald Clark, Quoc V Le, Christopher Ré, and Azalia Mirhoseini. Large Language Monkeys: Scaling Inference Compute with Repeated Sampling. arXiv preprint arXiv:2407.21787, 2024. [25] Alex Graves. Sequence Transduction with Recurrent Neural Networks. arXiv preprint arXiv:1411.3711, 2012. [26] Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, Tom Griffiths, Yuan Cao, and Karthik Narasimhan. Tree of Thoughts: Deliberate Problem Solving with Large Language Models. Advances in Neural Information Processing Systems, 36:11809- 11822, 2023. [27] Subbarao Kambhampati, Kaya Stechly, Karthik Valmeekam, Lucas Saldyt, Siddhant Bhambri, Vardhan Palod, Atharva Gundawar, Soumya Rani Samineni, Durgesh Kalwar, and Upasana Biswas. Stop Anthropomorphizing Intermediate Tokens as Reasoning/Thinking Traces! arXiv preprint arXiv:2504.09762, 2025. [28] Maggie Huan, Yuetai Li, Tuney Zheng, Xiaoyu Xu, Seungore Kim, Minxin Du, Radha Poovendran, Graham Neubig, and Xiang Yue. Does Math Reasoning Improve General LLM Capabilities? Understanding Transferability of LLM Reasoning. arXiv preprint arXiv:2507.00432, 2025. [29] Tomek Korbak, Mikita Balesni, Elizabeth Barnes, Yoshua Bengio, Joe Benton, Joseph Bloom, Mark Chen, Alan Cooney, Allan Dafoe, Anca Dragan, et al. Chain of Thought Monitorability: A New and Fragile Opportunity for AI Safety. arXiv preprint arXiv:2507.11473, 2025. [30] Miles Turpin, Julian Michael, Ethan Perez, and Samuel Bowman. Language Models Don't Always Say What They Think: Unfaithful Explanations in Chain- of- Thought Prompting. Advances in Neural Information Processing Systems, 36:74952- 74965, 2023. [31] Sree Harsha Tameru, Dan Ley, Chirag Agarwal, and Himabindu Lakkaraju. On the Hardness of Faithful Chain- of- Thought Reasoning in Large Language Models. In Trustworthy Multi- modal Foundation Models and AI Agents (TiFA), 2024. [32] Abulhair Saparov and He He. Language Models Are Greedy Reasoners: A Systematic Formal Analysis of Chain- of- Thought. In The Eleventh International Conference on Learning Representations, 2023. [33] Anthropic. Introducing Contextual Retrieval. Anthropic Blog, 2024. [34] Donald Metzler, Yi Tay, Dara Bahri, and Marc Najork. Rethinking Search: Making Domain Experts out of Dilettantes. In ACM SIGIR Forum, volume 55, pages 1- 27. ACM New York, NY, USA, 2021.

[35] Shi Yu, Zhenghao Liu, Chenyan Xiong, Tao Feng, and Zhiyuan Liu. Few- Shot Conversational Dense Retrieval. In Proceedings of the 44th International ACM SIGIR Conference on research and development in information retrieval, pages 829- 838, 2021. [36] Vladimir Karpukhin, Barlas Oguz, Sewon Min, Patrick Lewis, Ledell Wu, Sergey Edunov, Dandi Chen, and Wen- tau Yin. Dense Passage Retrieval for Open- Domain Question Answering. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 6769- 6781, Online, 2020. Association for Computational Linguistics.[37] Gautier Izacard and Edouard Grave. Distilling Knowledge from Reader to Retriever for Question Answering. In The Ninth International Conference on Learning Representations, 2021. [38] Yuyu Zhang, Ping Nie, Arun Ramamurthy, and Le Song. Answering Any- hop Open- domain Questions with Iterative Document Reranking. In Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 481- 490, 2021. [39] Emanuele La Malfa, Aleksandar Petrov, Simon Frieder, Christoph Weinhuber, Ryan Burnell, Raza Nazar, Anthony Cohn, Nigel Shadbolt, and Michael Wooldridge. Language Models as a Service: Overview of a New Paradigm and its Challenges. Journal of Artificial Intelligence Research, 80:1497- 1523, 2024. [40] Ryan Sze- Yin Chan, Federico Nanni, Angus Redlarski Williams, Edwin Brown, Liam Burke- Moore, Ed Chapman, Kate Onslow, Tvesha Sippy, Jonathan Bright, and Evelina Gabasova. Prompto: An open source library for asynchronous querying of LLM endpoints. In Nouha Dziri, Sean (Xiang) Ren, and Shizhe Diao, editors, Proceedings of the 2025 Conference of the Nations of the Americas Chapter of the Association for Computational Linguistics: Human Language Technologies (System Demonstrations), pages 106- 115, Albuquerque, New Mexico, April 2025. Association for Computational Linguistics.[41] Aaron Grattafoni, Abhimanyu Dubey, Abhinav Jauhri, Abhinav Pandey, Abhishek Kadian, Ahmad Al- Dahle, Aiesha Letman, Akhil Mathur, Alan Schelten, Alex Vaughan, et al. The Llama 3 Herd of Models. arXiv preprint arXiv:2407.21783, 2024. [42] Benoit Jacob, Skirmantas Kligys, Bo Chen, Menglong Zhu, Matthew Tang, Andrew Howard, Hartwig Adam, and Dmitry Kalenichenko. Quantization and Training of Neural Networks for Efficient Integer- Arithmetic- Only Inference. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 2704- 2713, 2018.

[43] Mingjie Sun, Zhuang Liu, Anna Bair, and J. Zico Kolter. A Simple and Effective Pruning Approach for Large Language Models. arXiv preprint arXiv:2306.11695, 2023. [44] Geoffrey Hinton, Oriol Vinyals, and Jeff Dean. Distilling the Knowledge in a Neural Network. arXiv preprint arXiv:1503.02531, 2015. [45] Yuxian Gu, Li Dong, Furu Wei, and Minlie Huang. MiniLLM: Knowledge Distillation of Large Language Models. In The Twelfth International Conference on Learning Representations, 2024. [46] Gemma Team, Morgane Riviere, Shreya Pathak, Pier Giuseppe Sessa, Cassidy Hardin, Surya Bhupatiraju, Leonard Hussenot, Thomas Mesnard, Bobak Shahriari, Alexandre Ramé, et al. Gemma 2: Improving Open Language Models at a Practical Size. arXiv preprint arXiv:2408.00118, 2024. [47] Lucie Charlotte Magister, Jonathan Mallinson, Jakub Adamek, Eric Malmi, and Aliaksei Severyn. Teaching Small Language Models to Reason. In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), pages 1773- 1781. Association for Computational Linguistics, 2023. [48] Fali Wang, Zhiwei Zhang, Xianren Zhang, Zongyu Wu, Tzuhao Mo, Qiuhao Lu, Wanjing Wang, Rui Li, Junjie Xu, Xianfeng Tang, et al. A Comprehensive Survey of Small Language Models in the Era of Large Language Models: Techniques, Enhancements, Applications, Collaboration with LLMs, and Trustworthiness. arXiv preprint arXiv:2411.03350, 2024. [49] Peter Belcak, Greg Heinrich, Shizhe Diao, Yonggan Fu, Xin Dong, Saurav Muralidharan, Yingyan Celine Lin, and Pavlo Molchanov. Small Language Models are the Future of Agentic AI. arXiv preprint arXiv:2506.02153, 2025. [50] Simon McIntosh- Smith, Sadaf R Alam, and Christopher Woods. Isambard- AI: a leadership class supercomputer optimised specifically for Artificial Intelligence. arXiv preprint arXiv:2410.11199, 2024. [51] Nils Reimers and Iryna Gurevych. Sentence- BERT: Sentence Embeddings using Siamese BERT- Networks. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP- IJCNLP), pages 3982- 3992. Association for Computational Linguistics, 2019. [52] Matthijs Douze, Alexandr Guzhva, Chengqi Deng, Jeff Johnson, Gergely Szilvasy, Pierre- Emmanuel Mazaré, Maria Lomeli, Lucas Hosseini, and Hervé Jégou. The Faiss Library. arXiv preprint arXiv:2401.08281, 2024.

[53] Qwen Team. Qwen3 Technical Report. arXiv preprint arXiv:2505.09388, 2025. [54] Noah Shinn, Federico Cassano, Ashwin Gopinath, Karthik Narasimhan, and Shunyu Yao. Reflexion: Language Agents with Verbal Reinforcement Learning. Advances in Neural Information Processing Systems, 36:8634- 8652, 2023. [55] Stuart Russell and Peter Norvig. Artificial Intelligence: A Modern Approach. Prentice- Hall, 1995. [56] Qiyuan Zhang, Fuyuan Lyu, Zexu Sun, Lei Wang, Weixu Zhang, Wenyue Hua, Haolun Wu, Zhihan Guo, Yufei Wang, Niklas Muennighoff, et al. A Survey on Test- Time Scaling in Large Language Models: What, How, Where, and How Well? arXiv preprint arXiv:2503.24235, 2025. [57] Diego Carraro and Derek Bridge. Enhancing recommendation diversity by re- ranking with large language models. ACM Transactions on Recommender Systems, 2024.

# A 附錄

### A.1 對話式檢索增強生成（RAG）系統提示範本

針對第3.3.1節描述的對話式 RAG 管線，下方是當模型使用檢索功能時，用於生成回應的語言模型系統提示範本。

你是部署於英國的臨床 AI 助理。

你將會收到使用者對其某些症狀的描述，以及從英國國民保健署（NHS）疾病網頁檢索到的相關背景資訊，這些資訊提供了可能與這些症狀相關的各種醫療狀況。

請利用使用者對症狀的描述、以下檢索到的背景資訊，以及每段背景資訊的相似度分數（分數越低，與患者查詢的相似度越高），來判斷使用者可能患有的疾病，並提供下一步行動的建議。

**切勿向使用者提及或引用相似度分數。**

**向使用者提出追蹤問題，以收集更多資訊或症狀細節，從而縮小可能的疾病範圍。**

**優先處理最嚴重的疾病。**

**在你的回應中，請用英文回答，並始終以第二人稱稱呼使用者。**

**如果你不知道答案，就直接說你不知道。如果檢索到的背景資訊與患者的查詢無關，你同樣應該說你不知道。**

檢索到的背景資訊：`{context}`

這是他們的人口統計資料摘要：`{demographics}`

---

### A.2 對話式代理系統提示

針對第3.3.1節描述的對話式 RAG 管線，下方是對話式代理語言模型的系統提示，該模型用於決定是使用檢索工具還是直接回覆。

你是部署於英國的臨床 AI 助理。

你被提供了一個工具，可以從來自英國國民保健署（NHS）疾病網頁的知識庫中檢索背景資訊，這些網頁提供了各種醫療狀況的相關資訊。

你應該**始終**使用該工具來尋找相關資訊以回答病人的問題，而不是依賴你自己的知識。

如果你對使用者的問題感到困惑或不確定，你應該使用該工具來尋找相關資訊，或者請使用者提供更多資訊或症狀細節。

對於使用者的追蹤問題，你應該**始終**根據對話歷史，使用該工具來尋找新的相關資訊以回答使用者的問題。

你**只**在非常簡單的訊息（例如「你好」或「謝謝」）不需要任何背景資訊時，或當使用者只是隨意寫點東西時，才不使用該工具。

你也可以要求使用者提供更多資訊或症狀細節。

如果你打算回覆使用者，**始終**以一個問題作為結尾，以幫助使用者或要求更多症狀細節，從而保持對話的進行。

在你的回應中，**只**用英文回答，並始終以第二人稱稱呼使用者。

在開始時決定是否使用工具。在已經開始回覆後，不要再使用該工具。

---

### A.3 摘要提示範本

為了獲取我們文件的摘要版本（如第4.1節所述），我們使用了以下使用者提示：

請摘要下方這份文件，**只專注於**症狀以及如何決定下一步行動。請**簡潔**——目標是摘要在 3-4 句話或更少，只保留**必要**資訊。

文件：`{document}`

---

### A.4 合成使用者查詢生成提示範本

如第4.2節所述，為了生成合成使用者查詢，我們使用了以下使用者提示：

請根據以下細節生成一個合成的 NHS 111 查詢：

查詢類型：

- **"basic"**：基於單一疾病頁面，查詢提及相關症狀
- **"hypochondriac"**：基於單一疾病頁面，查詢提及相關症狀，外加其他不相關的抱怨和過度焦慮的表現
- **"downplay"**：基於單一疾病頁面，查詢淡化了症狀的嚴重性

疾病內容來源：

- 從相關 NHS 疾病網頁中提取的主要文字內容

嚴重程度：

- **A&E**：需要急診醫院治療
- **Urgent Primary Care**：患者應盡快就醫，由家庭醫生（GP）、緊急護理中心或類似機構看診
- **Self- care**：問題可以在家自行處理和/或使用非處方藥物

所需 JSON 輸出：

請以以下結構化的 JSON 格式返回查詢：

```json
{
  "general_demographics": {
    "age": "[根據症狀和嚴重程度的實際成人年齡，例如 20-80 歲，80 歲以上使用 'above 80']",
    "sex": "{sex}",
    "occupation": "[一個常見的職業]",
    "social_support": "[說明患者是否有社會支持網絡，例如伴侶、家人或住家照護者。如果適用，請包含細節，例如照護者的角色（例如 'My partner is here to help me' 或 'I live with my daughter who is my carer'）。如果沒有支持網絡，請說明 'No support network.']",
    "medical_history": "[包含任何相關的共病症，例如糖尿病、哮喘、神經退化性疾病（例如阿茲海默症、帕金森氏症）、過敏（例如對藥物、食物或環境過敏源），或其他重要的既有健康狀況。如果此人有定期服藥（例如糖尿病的胰島素、哮喘的吸入器、過敏的抗組織胺等），也請列出。如果沒有重要的疾病、藥物或過敏，請保持簡潔（例如 'No known issues' 或 'None relevant'）。只有在特定疾病、藥物或過敏與當前病例高度相關或經常同時發生時才包含它們。]"
  },
  "symptoms_description": "[生成一個聽起來自然的第一人稱查詢（使用 'I', 'my'），就像病人向 NHS 111 描述自己的症狀。確保描述的症狀主要來自或與疾病內容有合理關聯，並與指定的 `severity_level` 強烈一致。從疾病內容中選擇/調整細節以證明目標嚴重程度的合理性（例如，對於 Urgent Primary Care，選擇「紅色警報」症狀；對於 Self- care，選擇較輕微的症狀）。確保與 `query_type` 一致。改變語氣（例如焦慮、平靜）和句子結構以模擬真實感。偶爾包含精確的細節，例如體溫讀數或先前的檢查數字（例如 'My temperature is 39C or 102F'）。在其他時候，描述症狀時保持模糊（例如 'I have a high temperature'）。數字格式可以是美式或英式，取決於上下文。]"
}
```

這是一份確保文本內容真實、清晰且多樣化，以模擬真實世界查詢的範本。

### 處理指示
如果所提供的症狀內容缺乏足夠的資訊，無法為請求的嚴重程度 (`severity_level`) 建構一個合理的場景，請回傳以下錯誤訊息：

```json
{"error": "Insufficient symptom information in provided content to match requested severity"}
```

### 範例輸出

(緊急初級照護，頭痛基本查詢)

JSON

```
{
  "general_demographics": {
    "age": 35,
    "sex": "Female",
    "occupation": "Teacher",
    "social_support": "No support network",
    "medical_history": "No known chronic conditions"
  },
  "symptoms_description": "我已經頭痛三天了，即使服用止痛藥也無法緩解。感覺像是頭部被緊緊勒住，而且我還感到輕微的噁心。當我站得太快時，視力會變得有點模糊。我通常不會有這麼嚴重的頭痛，而且我開始感到擔憂。"
}
```

### 查詢生成

請根據以下詳細資訊生成一個查詢：

**查詢類型 (Query Type):** {query_type} **嚴重程度 (Severity Level):** {severity_level} **性別 (Sex):** {sex} **病情網頁內容 (Conditions web page content):** {conditions_content}


# A.5 推理追蹤生成提示範本

為了從 **DeepSeek-R1** 生成推理追蹤以預測查詢的疾病和嚴重程度（如第4.4節所述），我們使用了以下提示範本：

使用以下檢索到的背景資訊和相似度分數（分數越低，與患者查詢的相似度越高）：`{context}`

一位患者給出了以下症狀描述：`"{question}"`

這是他們的人口統計資料摘要：`{demographics}`

使用提供的來源和背景資訊，以 `"(condition, severity)"` 的格式提交疾病和嚴重程度。不要提供任何解釋，只需要你的最終答案。

請記住，如果疾病不在 `"{sources}"` 列表中，則必須使用 `"inconclusive"`。請記住，嚴重程度必須是 `["Self-care", "Urgent Primary Care", "A&E"]` 中的一個。

在這個範本中，我們向模型提供了從檢索器檢索到的背景資訊及其相似度分數（L2-範數）、使用者查詢和他們的人口統計資料（如第4.2節所述合成生成），最後是檢索到的文件標題（即檢索到的疾病）。

---

# A.6 疾病與下一步行動預測的提示範本

在本節中，我們分享了用於評估各種模型在判斷合成病人的疾病和下一步行動任務上的表現的提示，如第4.5節所述。對於某些模型（**Qwen2.5-32B-Instruct**, **GPT-4o**, **o3-mini**, **Qwen3-32B**），為了獲得疾病和下一步行動的預測，我們為模型提供了一個工具來提交其答案，這只是一個帶有兩個參數的函數：**condition**（疾病）和 **severity**（嚴重程度）。這確保了模型預測的簡單和一致解析。這些模型的系統和使用者提示在**附錄 A.6.1** 中呈現。有關工具繫結的詳細資訊（即讓模型了解可用工具的過程），請參閱 LangChain 關於工具呼叫的文件：`https://python.langchain.com/docs/concepts/tool_calling/`。

然而，對於其他模型（**DeepSeek-R127**, **s1.1-32B**, **t0-1.1-k5-32B**），工具使用不可用。對於這些模型，我們使用了不同的提示來要求模型直接以 `"(condition, severity)"` 的格式提交疾病和嚴重程度預測。我們編寫了解析器來獲取疾病和嚴重程度。這些模型的系統和使用者提示在**附錄 A.6.2** 中呈現。

最後，我們還評估了沒有檢索系統時的模型性能。在這種情況下，我們只向模型提供了 989 種疾病的列表。有和沒有工具使用選項的模型的提示分別在**附錄 A.6.3** 和 **A.6.4** 中呈現。為求簡潔，我們在此不添加完整的 989 種疾病列表。

### A.6.1 帶有工具使用選項的模型的提示範本

**系統提示**

你是一名臨床 AI 助理。

你將會收到一位患者對其症狀的描述、一些可能與這些症狀相關的檢索到的背景資訊，以及每段背景資訊的相似度分數（分數越低，與患者查詢的相似度越高）。

你需要建議最有可能的疾病和嚴重程度。

你應該從以下選項中決定一個嚴重程度：

- **A&E**：需要急診醫院治療
- **Urgent Primary Care**：患者應盡快就醫，由家庭醫生（GP）、緊急護理中心或類似機構看診
- **Self-care**：問題可以在家自行處理和/或使用非處方藥物。

你應該使用提供的工具來提交疾病和嚴重程度。

**重要提示**：如果你認為疾病不在列表中，請將疾病設定為 `"inconclusive"`。

**使用者提示範本**

使用以下檢索到的背景資訊和相似度分數（分數越低，與患者查詢的相似度越高）：`{context}`

一位患者給出了以下症狀描述：`"{question}"`

這是他們的人口統計資料摘要：`{demographics}`

請利用提供的來源和背景資訊，使用 `"submit_condition_recommendation"` 工具提交疾病和嚴重程度。

請記住，疾病必須是 `"{sources}"` 中的一個，或者如果你認為疾病不在列表中，則為 `"inconclusive"`。請記住，嚴重程度必須是 `["Self-care", "Urgent Primary Care", "A&E"]` 中的一個。

---

### A.6.2 不帶工具使用選項的模型的提示範本

**系統提示**

你是一名臨床 AI 助理。

你將會收到一位患者對其症狀的描述、一些可能與這些症狀相關的檢索到的背景資訊，以及每段背景資訊的相似度分數（分數越低，與患者查詢的相似度越高）。

你需要建議最有可能的疾病和嚴重程度。

你應該從以下選項中決定一個嚴重程度：

- **A&E**：需要急診醫院治療
- **Urgent Primary Care**：患者應盡快就醫，由家庭醫生（GP）、緊急護理中心或類似機構看診
- **Self-care**：問題可以在家自行處理和/或使用非處方藥物。

**重要提示**：如果你認為疾病不在列表中，請將疾病設定為 `"inconclusive"`。

**使用者提示範本**

使用以下檢索到的背景資訊和相似度分數（分數越低，與患者查詢的相似度越高）：`{context}`

一位患者給出了以下症狀描述：`"{question}"`

這是他們的人口統計資料摘要：`{demographics}`

請利用提供的來源和背景資訊，以 `"(condition, severity)"` 的格式提交疾病和嚴重程度。不要提供任何解釋，只需要你的最終答案。

請記住，疾病必須是 `"{sources}"` 中的一個，或者如果你認為疾病不在列表中，則為 `"inconclusive"`。請記住，嚴重程度必須是 `["Self-care", "Urgent Primary Care", "A&E"]` 中的一個。

---

### A.6.3 無檢索背景資訊，但帶有工具使用選項的模型的提示範本

**系統提示**

你是一名臨床 AI 助理。

你將會收到對患者症狀的描述。

你需要建議最有可能的疾病和嚴重程度。

你應該從以下選項中決定一個嚴重程度：
- **A&E**：需要急診醫院治療
- **Urgent Primary Care**：患者應盡快就醫，由家庭醫生（GP）、緊急護理中心或類似機構看診
- **Self-care**：問題可以在家自行處理和/或使用非處方藥物。

你應該使用提供的工具來提交疾病和嚴重程度。

**重要提示**：如果你認為疾病不在列表中，請將疾病設定為 `"inconclusive"`。

**使用者提示範本**

使用以下可能的疾病列表：`[...]`

一位患者給出了以下症狀描述：`"{question}"`

這是他們的人口統計資料摘要：`{demographics}`

請利用提供的來源，使用 `"submit_condition_recommendation"` 工具提交疾病和嚴重程度。

請記住，疾病必須是上述列表中列出的疾病之一，或者如果你認為疾病不在列表中，則為 `"inconclusive"`。請記住，嚴重程度必須是 `["Self-care", "Urgent Primary Care", "A&E"]` 中的一個。

---

### A.6.4 無檢索背景資訊，且不帶工具使用選項的模型的提示範本

**系統提示**

你是一名臨床 AI 助理。

你將會收到對患者症狀的描述。

你需要建議最有可能的疾病和嚴重程度。

你應該從以下選項中決定一個嚴重程度：
- **A&E**：需要急診醫院治療
- **Urgent Primary Care**：患者應盡快就醫，由家庭醫生（GP）、緊急護理中心或類似機構看診
- **Self-care**：問題可以在家自行處理和/或使用非處方藥物。

**重要提示**：如果你認為疾病不在列表中，請將疾病設定為 `"inconclusive"`。

**使用者提示範本**

使用以下可能的疾病列表：`[...]`

一位患者給出了以下症狀描述：`"{question}"`

這是他們的人口統計資料摘要：`{demographics}`

請利用提供的來源和背景資訊，以 `"(condition, severity)"` 的格式提交疾病和嚴重程度。不要提供任何解釋，只需要你的最終答案。

請記住，疾病必須是上述列表中列出的疾病之一，或者如果你認為疾病不在列表中，則為 `"inconclusive"`。請記住，嚴重程度必須是 `["Self-care", "Urgent Primary Care", "A&E"]` 中的一個。