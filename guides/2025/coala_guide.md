# **《語言代理的認知架構》（CoALA）論文導讀**

本文是對《用於語言代理的認知架構》（*Cognitive Architectures for Language Agents, CoALA*）這篇論文的詳細導讀，該論文提出了一個概念性框架，旨在組織現有的語言代理（Language Agents）並指導未來的發展。

## **1. 簡介與背景**

* **語言代理的興起**：語言代理是一種新興的人工智慧系統，它們利用大型語言模型（*LLMs*）與世界互動。這些代理結合了 LLMs 的能力和現有的代理設計領域。

* **LLMs 與傳統代理的局限性及其互補性**：LLMs 本身知識和推理能力有限。語言代理透過將 LLMs 連接到內部記憶和外部環境來彌補這些問題，使 LLMs 能與現有知識或外部觀察結果接軌。

    傳統代理通常需要手工編寫規則或強化學習，導致難以推廣到新環境。語言代理利用 LLMs 中存在的常識先驗知識來適應新任務，減少對人工標註或試錯學習的依賴。

* **當前挑戰**：雖然最新的**認知語言代理**採用了複雜的內部處理方式（例如推理、規劃、長期記憶管理），但不同的研究工作使用自訂術語來描述這些過程，導致難以比較、理解其演變或建立具有清晰一致抽象的新代理。

* **歷史借鑑**：為了解決這一問題，論文從計算機科學和人工智慧的歷史中汲取靈感，特別是**生產系統**（*production systems*）和**認知架構**（*cognitive architectures*）。

    * **生產系統**：由一組規則組成，每個規則指定一個前提條件和一個動作。當前提條件滿足時，即可執行該動作。它們最初用於描述字串操作，後來被 AI 社群用於定義具有複雜、層次結構行為的系統。
    * **認知架構**：在生產系統的基礎上，定義了選擇、應用甚至生成新生產規則的控制流程。它們透過明確地實例化感知、記憶和規劃等過程來模仿人類認知，以實現靈活、理性、即時的行為。*Soar* 架構是一個典型的例子，它包含工作記憶、長期記憶（程序記憶、語義記憶、情節記憶）以及決策循環。

* **LLMs 與生產系統的連結**：論文提出 LLMs 可以被視為**機率性生產系統**。LLMs 根據輸入（提示）定義了對字串擴展或修改的機率分佈。

    * **提示工程**（*Prompt Engineering*）被視為控制流程。透過在輸入字串中添加額外文本，可以將 LLM 偏向於高品質的生產，這本身就可以被視為一系列的生產。
    * **認知語言代理的演進**：語言代理超越了預定義的提示鏈，將 LLM 置於與外部環境的互動回饋迴圈中，並利用 LLM 進行內部推理和學習。

## **2. CoALA 框架：核心概念**

CoALA 是一個概念框架，用於描述和設計通用語言代理。它將 LLM 定位為整個認知架構的核心組件。CoALA 沿著三個關鍵維度組織代理：

### **2.1 記憶模組** (*Memory Modules*)

語言模型本身是無狀態的，而語言代理則需要內部儲存和維護資訊以實現多步驟互動。CoALA 框架將資訊組織到多個記憶模組中：

* **工作記憶** (*Working Memory*)：維持當前決策週期中活躍且隨時可用的資訊，包括感知輸入、活動知識（由推理或從長期記憶中檢索而來）以及從上一個決策週期結轉的核心資訊（例如代理的活動目標）。
    > 它是連接語言代理不同組件的核心樞紐，在每次 LLM 呼叫時，輸入會從工作記憶的子集中合成，LLM 輸出則被解析回工作記憶中的變數，用於執行相應的動作。

* **情節記憶** (*Episodic Memory*)：儲存早期決策週期中的經驗，例如訓練輸入-輸出對、歷史事件流程或遊戲軌跡。在規劃階段，這些情節可以被檢索到工作記憶中以支持推理。代理也可以將新經驗寫入情節記憶作為學習的一種形式。

* **語義記憶** (*Semantic Memory*)：儲存代理關於世界和自身的知識。
    > 傳統方法通常從外部資料庫初始化語義記憶（例如，檢索增強方法中的維基百科），作為固定、只讀的記憶。
    > 語言代理也可以將從 LLM 推理獲得的新知識寫入語義記憶，作為一種學習形式，以從經驗中逐步建立世界知識。

* **程序記憶** (*Procedural Memory*)：包含兩種形式：*LLM 權重中儲存的隱性知識*，以及*代理程式碼中明確編寫的顯性知識*。
    * 代理程式碼進一步分為：實現動作的程序（推理、檢索、接地和學習程序）和實現決策本身的程序。
    * 與情節或語義記憶不同，程序記憶必須由設計者用適當的程式碼初始化，才能啟動代理。
    * 透過寫入程序記憶來學習新動作是可能的，但風險較高，可能引入錯誤或讓代理偏離設計者的意圖。

### **2.2 結構化行動空間** (*Structured Action Space*)

代理的動作空間分為內部和外部兩部分：

* **外部動作（接地行動** *Grounding Actions* **）**：與外部環境互動，並將環境回饋處理為文本形式的工作記憶。可分為三種環境類型：
    1.  **實體環境** (*Physical Environments*)：例如控制機器人，將感知輸入（視覺、聽覺、觸覺）處理為文本觀察結果。
    2.  **與人類或其他代理的對話** (*Dialogue with Humans or Other Agents*)：允許代理接受指令、向人類學習，或請求幫助、澄清，甚至與其他語言代理互動以進行社會模擬或協作任務解決。
    3.  **數位環境** (*Digital Environments*)：包括與遊戲、API 和網站互動，以及通用程式碼執行。這是一種更經濟、更快速的測試平台。

* **內部動作** (*Internal Actions*)：與內部記憶互動。
    * **檢索行動** (*Retrieval Actions*)：將資訊從長期記憶讀入工作記憶。例如，從技能庫中載入程式碼技能，或從情節記憶中檢索相關事件。
    * **推理行動** (*Reasoning Actions*)：處理工作記憶的內容以產生新資訊。它與檢索不同，推理讀取並寫入工作記憶，用於總結和提煉觀察結果、軌跡或從長期記憶中檢索到的資訊。
    * **學習行動** (*Learning Actions*)：透過將資訊寫入長期記憶來發生。這包括：
        * 用經驗更新情節記憶：儲存情節軌跡以供未來推理或決策。
        * 用知識更新語義記憶：推理原始經驗並將結果（推論）儲存為語義知識。
        * 更新 LLM 參數（程序記憶）：透過微調 LLM 權重以適應特定領域，這是一種代價較高的學習形式。
        * 更新代理程式碼（程序記憶）：CoALA 允許代理更新其原始程式碼，從而修改各種程序的實作（例如，更新提示模板、程式碼技能）。

### **2.3 廣義決策過程** (*Generalized Decision-Making Process*)

語言代理透過決策過程選擇動作，這遵循一個重複的循環：

* **決策週期** (*Decision Cycle*)：定義了代理的頂層程式，產生外部接地行動或內部學習行動。
    * **規劃階段** (*Planning Stage*)：在這個階段，推理和檢索可以靈活應用，以提出、評估和選擇替代方案。
        * **提案** (*Proposal*)：生成一個或多個動作候選。
        * **評估** (*Evaluation*)：如果提出多個動作，則為每個動作賦予價值，這可以透過啟發式規則、LLM 推理或組合方式完成。
        * **選擇** (*Selection*)：根據動作的價值，選擇一個動作執行，或拒絕並回到提案步驟。
    * **執行階段** (*Execution Stage*)：執行所選動作的相關程序。這可以是外部接地行動（例如 API 呼叫）或內部學習行動（例如寫入情節記憶）。隨後會從環境中獲得觀察結果，提供行動的回饋，然後循環再次開始。

## **3. 案例研究**

CoALA 框架可以清晰地描述各種語言代理，揭示它們在內部機制上的異同：

* **SayCan**：接地於機器人互動，只有**程序記憶**（LLM 和學習到的價值函數）和外部動作（固定技能集），透過 LLM 和學習到的價值評估每個動作來進行單步規劃。

* **ReAct**：接地於數位環境，缺乏**語義或情節記憶**，因此沒有檢索或學習動作。其動作空間包括內部**推理**和外部**接地**。決策週期固定為先推理，然後生成接地動作，沒有評估或選擇階段。

* **Voyager**：接地於 Minecraft API，擁有長期**程序記憶**（技能庫）。其動作空間包含接地、推理、檢索和學習（新增接地程序）。它能推理目標、提出程式碼技能，並根據環境回饋決定是否學習新技能或改進現有程式碼。

* **Generative Agents**：接地於沙盒遊戲，動作空間包含所有四種類型。代理具有長期**情節記憶**，透過檢索和推理生成對情節記憶的反思，並寫入**語義記憶**。決策時，檢索語義記憶中的反思，規劃一天的高層次計畫，並在執行過程中根據觀察調整計畫。

* **Tree of Thoughts (ToT)**：一種特殊的語言代理，只有一個外部動作（提交最終解決方案），沒有長期記憶，內部動作空間只有**推理**。其決策過程非常審慎，透過樹狀搜索演算法迭代地提出、評估和選擇「思維」（推理動作），以實現全局探索以及局部回溯和預見。

## **4. 可行的洞見與未來方向**

CoALA 提供了一套理論框架，為語言代理的發展提供了獨特而互補的實踐建議：

* **模組化代理**：建議代理應結構化和模組化，以實現標準化、可重複使用和改進兼容性。建議實作抽象概念（如記憶、動作、代理類別）以促進更複雜代理的構建。
    * 強調在代理設計中，程式碼（*確定性規則*）應補充 LLM 的局限性（例如，實作樹搜索以緩解自迴歸生成引起的近視）。

* **代理設計超越簡單推理**：透過 CoALA 概念（記憶、動作、決策），為特定應用設計代理。
    * 確定必要的記憶模組、定義讀寫權限，並設計決策過程，在性能和泛化能力之間取得平衡。

* **結構化推理超越提示工程**：建議使用更高層次的框架來定義推理步驟，並透過結構化輸出解析來更新工作記憶變數。
    * 代理中的推理用例可以反過來指導 LLM 的訓練，使其針對代理應用中已證明有用的新推理模式進行優化。

* **長期記憶超越檢索增強**：記憶增強型語言代理可以讀取和寫入自動生成的內容，實現高效的終身學習。
    * 結合現有知識和新經驗，逐步建立知識庫和程式碼庫。
    * 將檢索和推理相結合，以更好地規劃。

* **學習超越情境學習或微調**：CoALA 將「學習」定義為決策週期的結果動作。
    * 未來的方向包括透過修改代理程式碼進行**元學習**（例如學習更好的檢索程序）、引入新的學習和「遺忘」形式（例如微調小型模型、刪除不必要的記憶項），以及研究多種學習形式之間的互動效應。

* **動作空間超越外部工具或動作**：明確定義內部（推理、檢索、學習）和外部（接地）動作的清晰且適合任務的動作空間。
    * 考慮動作空間的大小（更大能力意味著更複雜的決策問題）和安全性（學習和接地行動可能帶來內部或外部危害）。

* **決策超越動作生成**：這是語言代理最令人興奮的未來方向之一。
    * 整合語言推理和程式碼規劃，讓代理能夠即時編寫和執行模擬程式碼，以評估計畫的後果。
    * 將審慎推理擴展到現實世界場景。
    * 透過**元推理**提高效率，例如自適應分配計算資源和最佳化 LLM 呼叫。
    * 解決**校準**、**對齊**、**幻覺**和缺乏人機協作等問題，以提高 LLMs 作為代理骨幹的效用。

## **5. 討論與開放問題**

CoALA 還提出了一些重要的概念性開放問題：

* **LLMs vs. VLMs**：推理應該是純語言的還是多模態的？是採用模組化方法將感知資料轉換為文本，還是採用整合方法直接讓多模態模型推理圖像和文本？
* **內部 vs. 外部**：代理與環境的界限在哪裡？根據可控性和耦合度來區分內部記憶/動作與外部環境/動作。
* **實體 vs. 數位**：哪些差異值得關注？數位環境允許序列式和並行試驗，這可能導致不同於人類認知的決策過程。
* **學習 vs. 行動**：代理應如何持續自主學習？代理應將學習視為決策週期的一個結果行動，與接地行動同等重要，平衡學習與外部行動。
* **GPT-4 vs. GPT-N**：更強大的 LLMs 會如何改變代理設計？未來的 LLMs 可能會減少對程式碼規則和額外模型的需要，CoALA 可以作為概念指南來理解和解釋這些變化。

## **6. 結論**

總之，CoALA 框架提供了一個描述和構建語言代理的概念性藍圖。它從符號人工智慧和認知科學的豐富歷史中汲取靈感，將數十年來的見解與大型語言模型的前沿研究聯繫起來。論文認為，這種方法為發展更通用和更像人類的人工智慧提供了一條途徑。